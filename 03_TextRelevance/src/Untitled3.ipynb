{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsUrlsPath = '../data/urls.docs.txt'\n",
    "textdataPath = '../data/textdata'\n",
    "templateJson = '{:d}.json'\n",
    "queriesDocsPath = '../data/queries.docs.txt'\n",
    "queriesPath = '../data/queries.numerate.txt'\n",
    "\n",
    "pat = re.compile(r'\\d+')\n",
    "procNumbs = set(map(lambda x: int(pat.search(x).group(0)), os.listdir(textdataPath)))\n",
    "\n",
    "queriesDict = {}\n",
    "with open(queriesPath) as inputFile:\n",
    "    for line in inputFile:\n",
    "        number, query = line.strip().split('\\t')\n",
    "        queriesDict[number] = query\n",
    "        \n",
    "queriesDocsDict = json.load(open(queriesDocsPath))\n",
    "\n",
    "docsUrlsDict = {}\n",
    "with open(docsUrlsPath) as inputFile:\n",
    "    for line in inputFile:\n",
    "        number, url, path = line.strip().split('\\t')\n",
    "        docsUrlsDict[number] = (url, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfIdfBank:\n",
    "    tfIdfNumberPagesPath = '../data/tfIdfNumberPages'\n",
    "    tfIdfFeaturesPath = '../data/tfidfFeatutes'\n",
    "    \n",
    "    def __init__(self, tfIdfMatrix):\n",
    "        numberPages = json.load(open(TfIdfBank.tfIdfNumberPagesPath))\n",
    "        features = json.load(open(TfIdfBank.tfIdfFeaturesPath))\n",
    "        \n",
    "        self._indexPages = np.full(27000, -1, dtype=np.int)\n",
    "        self._indexPages[numberPages] = range(len(numberPages))\n",
    "        self._tfIdfMatrix = tfIdfMatrix#joblib.load(TfIdfFeatures.tfIdfPagesPath)        \n",
    "        self._indexFeatures = dict(map(lambda x: (x[1], x[0]), enumerate(features)))\n",
    "        \n",
    "    def tfidf(self, word, numberPage):\n",
    "        indexPage = self._indexPages[numberPage]\n",
    "        if indexPage == -1:\n",
    "            return None\n",
    "        indexFeature = self._indexFeatures.get(word.strip().lower(), -1)\n",
    "        if indexFeature == -1:\n",
    "            return 0\n",
    "        return self._tfIdfMatrix[indexPage, indexFeature]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "keywords = []\n",
    "descriptions = []\n",
    "for numb in procNumbs:\n",
    "    filename = templateJson.format(numb)\n",
    "    path = '{:s}/{:s}'.format(textdataPath, filename)\n",
    "    pageDict = json.load(open(path))\n",
    "    titles.append(pageDict[\"title\"])\n",
    "    keywords.append(pageDict[\"keywords\"])\n",
    "    descriptions.append(pageDict[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(titles, open('../data/subdata/titles', 'w'))\n",
    "json.dump(keywords, open('../data/subdata/keywords', 'w'))\n",
    "json.dump(descriptions, open('../data/subdata/description', 'w'))\n",
    "json.dump(procNumbs, open('../data/subdata/procNumbs', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = json.load(open('../data/subdata/titles'))\n",
    "keywords = json.load(open('../data/subdata/keywords'))\n",
    "descriptions = json.load(open('../data/subdata/description'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfIdfVectorizerPath = '../data/models/tfIdfVectorizer.pkl'\n",
    "tfIdfVect = joblib.load(tfIdfVectorizerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidfDicts = [{}, {}, {}]\n",
    "for i, data in enumerate([titles, keywords, descriptions]):\n",
    "    bank = TfIdfBank(tfIdfVect.transform(data))\n",
    "    for numb, query in queriesDict.items():\n",
    "        numbsDocs = queriesDocsDict[numb]\n",
    "        words = query.strip().split()\n",
    "        tfidfs = []\n",
    "        for numbDoc in numbsDocs:\n",
    "            if bank._indexPages[numbDoc] == -1:\n",
    "                tfidfs.append(None)\n",
    "            else:\n",
    "                tfidfs.append(sum(list(map(lambda x: bank.tfidf(x, numbDoc), words))))\n",
    "        tfidfDicts[i][numb] = tfidfs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titlePath = '../data/features/tfidfTitle'\n",
    "keywordsPath = '../data/features/tfidfKeywords'\n",
    "descPath = '../data/features/tfidfDesc'\n",
    "\n",
    "json.dump(tfidfDicts[0], open(titlePath, 'w'))\n",
    "json.dump(tfidfDicts[1], open(keywordsPath, 'w'))\n",
    "json.dump(tfidfDicts[2], open(descPath, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

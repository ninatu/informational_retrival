{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def NDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    best = DCGScore(y_true, y_true, k, gains)\n",
    "    actual = DCGScore(y_true, y_score, k, gains)\n",
    "    return actual / best\n",
    "\n",
    "def deltaNDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    max_DCG = DCGScore(y_true, y_true, k, gains)\n",
    "    order[np.argsort(y_score)[::-1]] = range(1, y_score.shape[0] + 1)\n",
    "    discounts = np.log2(order + 1)\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    elem_DCG = gains / discounts\n",
    "    _n = y_true.shape[0]\n",
    "    matr_elem_DCG = np.tile(elem_DCG, (_n, 1)).T\n",
    "    matr_swap_elem_DCG = gains.reshape((_n, 1)) / discounts.reshape((1, _n))\n",
    "\n",
    "    lambda_mtr = - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "    no_null_swap = ((order <= k).reshape((_n, 1)) + (order <= k).reshape((1, _n))) > 0\n",
    "    lambda_mtr = np.abs(lambda_mtr * no_null_swap)\n",
    "    if max_DCG != 0:\n",
    "        return lambda_mtr / max_DCG\n",
    "    else:\n",
    "        return lambda_mtr\n",
    "    \n",
    "def AverageNDCG(data, y_score, k):\n",
    "    ndcg = 0\n",
    "    for (indexs, y_true) in data:\n",
    "        ndcg += NDCGScore(y_true, y_score[indexs], k)\n",
    "    return ndcg / len(data)\n",
    "\n",
    "\n",
    "def CountErrorPair(data, y_score):\n",
    "    count_pair = 0\n",
    "    for (indexs, y_true) in data:\n",
    "        y_pred = y_score[indexs]\n",
    "        _n = y_pred.shape[0]\n",
    "\n",
    "        pairs = (y_pred.reshape((_n, 1)) - y_pred.reshape((1, _n))) <= 0\n",
    "        true_pairs = (y_true.reshape((_n, 1)) - y_true.reshape((1, _n))) > 0\n",
    "        count = sum(sum(pairs == true_pairs))\n",
    "        count_pair += count\n",
    "    return count_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relNormalize2(rel):\n",
    "    uniq_rel = np.unique(rel)\n",
    "    uniq_rel = sorted(uniq_rel)\n",
    "    norm_rel = np.empty(rel.shape)\n",
    "    for i, val in enumerate(uniq_rel):\n",
    "        norm_rel[rel==val] = i + 1\n",
    "    return norm_rel * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaRank:\n",
    "    def __init__(self, learning_rate, n_estimators, sigma, start_depth):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = []\n",
    "\n",
    "    def _createSet(self, DATA, queries, normalize):\n",
    "        all_queries = DATA[:, -1]\n",
    "        seq_x = []\n",
    "        data = []\n",
    "        last_index = 0\n",
    "        for q in queries:\n",
    "            X = DATA[all_queries == q, 1:-1]\n",
    "            seq_x.append(X)\n",
    "            data.append((range(last_index, last_index + X.shape[0]), normalize(DATA[all_queries == q, 0])))\n",
    "            last_index += X.shape[0]\n",
    "        return data, np.vstack(seq_x)\n",
    "\n",
    "    def fit(self, DATA, persent_valid, normalize, T_NDCG):\n",
    "        all_queries = DATA[:, -1]\n",
    "        uniq_queries = np.unique(all_queries)\n",
    "        #random.shuffle(uniq_queries)\n",
    "        uniq_queries = uniq_queries\n",
    "\n",
    "        count_valid = int(persent_valid * uniq_queries.shape[0])\n",
    "        valid_queries = uniq_queries[:count_valid]\n",
    "        train_queries = uniq_queries[count_valid:]\n",
    "\n",
    "        data_train, X_train = self._createSet(DATA, train_queries, normalize)\n",
    "        data_valid, X_valid = self._createSet(DATA, valid_queries, normalize)\n",
    "\n",
    "        self._trees = []\n",
    "        h_train = np.zeros(X_train.shape[0])\n",
    "        h_valid = np.zeros(X_valid.shape[0])\n",
    "\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            grad = np.zeros(h_train.shape)\n",
    "            for (indexs, y) in data_train:\n",
    "                h = h_train[indexs]\n",
    "                _n = h.shape[0]\n",
    "\n",
    "                delta_h = h.reshape((_n, 1)) - h.reshape((1, _n)) \n",
    "                sign_h = np.sign(y.reshape((_n, 1)) - y.reshape((1, _n)))\n",
    "                lambda_matr = self._sigma / (1 + np.exp(self._sigma * delta_h * sign_h))\n",
    "                # * deltaNDCGScore(y, h, T_NDCG)\n",
    "                lambda_vect = np.sum(sign_h * lambda_matr, axis=1)\n",
    "                grad[indexs] = lambda_vect\n",
    "\n",
    "            new_tree = DT(max_depth=self._start_depth)\n",
    "            new_tree.fit(X_train, grad)\n",
    "            self._trees.append(new_tree)\n",
    "\n",
    "            h_train += self._learning_rate * new_tree.predict(X_train)\n",
    "            h_valid += self._learning_rate * new_tree.predict(X_valid)\n",
    "\n",
    "            print(iteration,\n",
    "                  CountErrorPair(data_train, h_train),\n",
    "                  CountErrorPair(data_valid, h_valid),\n",
    "                  AverageNDCG(data_train, h_train, 5),\n",
    "                  AverageNDCG(data_valid, h_valid, 5),\n",
    "                  np.linalg.norm(grad))\n",
    "            iteration += 1\n",
    "            if (iteration == self._n_estimators):\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for tree in self._trees:\n",
    "            y_pred += self._learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LambdaRank:\n",
    "    def __init__(self, learning_rate, n_estimators, sigma, start_depth):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = []\n",
    "\n",
    "    def _createSet(self, DATA, queries, normalize):\n",
    "        all_queries = DATA[:, -1]\n",
    "        seq_x = []\n",
    "        data = []\n",
    "        last_index = 0\n",
    "        for q in queries:\n",
    "            X = DATA[all_queries == q, 1:-1]\n",
    "            seq_x.append(X)\n",
    "            data.append((range(last_index, last_index + X.shape[0]), normalize(DATA[all_queries == q, 0])))\n",
    "            last_index += X.shape[0]\n",
    "        return data, np.vstack(seq_x)\n",
    "\n",
    "    def fit(self, DATA, persent_valid, normalize, T_NDCG, _trees):\n",
    "        all_queries = DATA[:, -1]\n",
    "        uniq_queries = np.unique(all_queries)\n",
    "        #random.shuffle(uniq_queries)\n",
    "        uniq_queries = uniq_queries\n",
    "\n",
    "        count_valid = int(persent_valid * uniq_queries.shape[0])\n",
    "        valid_queries = uniq_queries[:count_valid]\n",
    "        train_queries = uniq_queries[count_valid:]\n",
    "\n",
    "        data_train, X_train = self._createSet(DATA, train_queries, normalize)\n",
    "        data_valid, X_valid = self._createSet(DATA, valid_queries, normalize)\n",
    "        self._learning_rate = 0.01\n",
    "        self._trees = _trees\n",
    "        h_train = self.predict(X_train)\n",
    "        h_valid = self.predict(X_valid)\n",
    "        self._learning_rate = 0.003\n",
    "\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            grad = np.zeros(h_train.shape)\n",
    "            for (indexs, y) in data_train:\n",
    "                h = h_train[indexs]\n",
    "                _n = h.shape[0]\n",
    "\n",
    "                delta_h = h.reshape((_n, 1)) - h.reshape((1, _n)) \n",
    "                sign_h = np.sign(y.reshape((_n, 1)) - y.reshape((1, _n)))\n",
    "                lambda_matr = self._sigma / (1 + np.exp(self._sigma * delta_h * sign_h))\n",
    "                # * deltaNDCGScore(y, h, T_NDCG)\n",
    "                lambda_vect = np.sum(sign_h * lambda_matr, axis=1)\n",
    "                grad[indexs] = lambda_vect\n",
    "\n",
    "            new_tree = DT(max_depth=self._start_depth)\n",
    "            new_tree.fit(X_train, grad)\n",
    "            self._trees.append(new_tree)\n",
    "\n",
    "            h_train += self._learning_rate * new_tree.predict(X_train)\n",
    "            h_valid += self._learning_rate * new_tree.predict(X_valid)\n",
    "\n",
    "            print(iteration,\n",
    "                  CountErrorPair(data_train, h_train),\n",
    "                  CountErrorPair(data_valid, h_valid),\n",
    "                  AverageNDCG(data_train, h_train, 5),\n",
    "                  AverageNDCG(data_valid, h_valid, 5),\n",
    "                  np.linalg.norm(grad))\n",
    "            iteration += 1\n",
    "            if (iteration == self._n_estimators):\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for tree in self._trees:\n",
    "            y_pred += self._learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    trainPath = \"../data/train.data.cvs\"\n",
    "    return DataFrame.from_csv(trainPath, index_col=False).as_matrix()\n",
    "\n",
    "def saveResults(queries, rels, namefile):\n",
    "    uniq_queries = np.unique(queries)\n",
    "    ans = np.empty((rels.shape[0], 2), dtype=np.int)\n",
    "    count_last = 1\n",
    "    for q in uniq_queries:\n",
    "        rel = rels[queries == q]\n",
    "        order = np.argsort(rel)[::-1] + count_last\n",
    "        ans[queries == q, 0] = order\n",
    "        ans[queries == q, 1] = q\n",
    "        count_last += rel.shape[0]\n",
    "    df = DataFrame(ans, columns=[\"DocumentId\",\"QueryId\"])\n",
    "    df.to_csv(open(namefile, \"w\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowData = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34748276 6131362 0.246551634974 0.253776974292 36767.1527454\n",
      "1 36988318 6605704 0.258614363416 0.265747155867 36402.6765257\n",
      "2 38512066 6910127 0.262650877625 0.270965992202 36156.8932731\n",
      "3 39233591 7051186 0.264880856598 0.277435292354 35954.97982\n",
      "4 40293056 7359024 0.26587125548 0.278547334087 35800.3248507\n",
      "5 40402499 7377574 0.266321941484 0.281148975062 35670.5634698\n",
      "6 40548975 7407477 0.27135391871 0.28443150753 35544.6610747\n",
      "7 40675535 7440957 0.271112547247 0.287488251254 35439.2053245\n",
      "8 40764496 7473136 0.272581850684 0.289164138312 35349.5298186\n",
      "9 40906059 7501762 0.274217600111 0.289880564394 35248.5832698\n",
      "10 41215171 7598295 0.276236094404 0.290373558514 35176.1100441\n",
      "11 41282093 7618288 0.277261869943 0.289637144334 35118.3851241\n",
      "12 41270282 7616448 0.278340201675 0.291352060268 35044.9527311\n",
      "13 41222404 7608474 0.279721724444 0.292691581547 34983.7732704\n",
      "14 41338483 7632174 0.280439846979 0.294906387541 34921.0497576\n",
      "15 41352620 7640352 0.283069862575 0.297708338905 34880.8468325\n",
      "16 41515697 7695014 0.283110466304 0.297105794843 34849.8430532\n",
      "17 41588898 7720411 0.284126381176 0.299295315792 34815.486887\n",
      "18 41648100 7738823 0.284227413217 0.301645991346 34776.2423413\n",
      "19 41704240 7758931 0.285403332847 0.301132162462 34738.8741762\n",
      "20 41741457 7773541 0.286945202987 0.300576550227 34699.647085\n",
      "21 41732435 7769233 0.287394000632 0.299333855591 34677.8572031\n",
      "22 41735044 7769894 0.288172561828 0.301243323288 34651.1941358\n",
      "23 41710049 7764796 0.289454218984 0.303178192664 34632.8344059\n",
      "24 41690785 7763910 0.290819551953 0.302387580179 34600.8913644\n",
      "25 41681658 7763076 0.290448396872 0.301905166837 34569.2458977\n",
      "26 41674152 7762656 0.290352454426 0.303545276964 34544.7711957\n",
      "27 41661380 7762473 0.291013822644 0.304577220181 34522.5442182\n",
      "28 41668474 7763980 0.29169165872 0.302750015682 34497.9049807\n",
      "29 41657651 7763864 0.291720905127 0.303712966997 34485.3626116\n",
      "30 41650323 7763852 0.292771978383 0.304552220462 34462.946504\n",
      "31 41639920 7762814 0.29152932225 0.305440357687 34443.7982598\n",
      "32 41611915 7758919 0.292561348288 0.305684967404 34427.5319864\n",
      "33 41592336 7758703 0.293272731371 0.306585046637 34408.5029755\n",
      "34 41579427 7758495 0.293375194019 0.305755146731 34377.2077593\n",
      "35 41571113 7759448 0.293563008132 0.306669825781 34365.0169675\n",
      "36 41565961 7758459 0.295587777616 0.308719345637 34351.6460054\n",
      "37 41558578 7757330 0.295967395452 0.308797086116 34342.2152167\n",
      "38 41552163 7757281 0.296445834016 0.30967106356 34331.3594452\n",
      "39 41541845 7756746 0.296902670266 0.309674092406 34320.663766\n",
      "40 41523507 7755292 0.296598984944 0.309730524734 34307.7271298\n",
      "41 41505597 7753232 0.296885282567 0.31088201092 34288.6760361\n",
      "42 41484679 7746735 0.297274436075 0.309749108452 34272.4525203\n",
      "43 41473534 7746669 0.297544309749 0.309626062731 34254.9956301\n",
      "44 41459255 7746505 0.297854455812 0.31202293152 34243.9612694\n",
      "45 41451118 7746991 0.298017772746 0.311635331337 34224.7411582\n",
      "46 41441106 7745433 0.297536564912 0.311177362571 34214.6785955\n",
      "47 41436724 7746593 0.297616466799 0.310254039772 34200.1932498\n",
      "48 41431501 7746718 0.2976901141 0.3113672355 34190.8502829\n",
      "49 41411135 7746072 0.298234511479 0.312694552397 34182.6256418\n",
      "50 41408707 7745195 0.298291923693 0.311788425175 34168.052756\n",
      "51 41403478 7744429 0.298492492166 0.312789371844 34157.7255296\n",
      "52 41386371 7743118 0.298405556461 0.312532423761 34151.2932056\n",
      "53 41372979 7741864 0.298183580687 0.312336494057 34131.2534777\n",
      "54 41365836 7740423 0.298532191775 0.313571312579 34121.3749801\n",
      "55 41357588 7740081 0.298575825162 0.313151320073 34111.8502241\n",
      "56 41351001 7739579 0.298925227808 0.313620395345 34103.2224002\n",
      "57 41333725 7737146 0.298682268502 0.313943612974 34092.9368518\n",
      "58 41329495 7736985 0.298645274426 0.314259439286 34080.6150401\n",
      "59 41322298 7736901 0.298823296424 0.313844137486 34074.4289402\n",
      "60 41316142 7735581 0.299979086438 0.314521820398 34069.826932\n",
      "61 41309851 7735006 0.300835346977 0.315018693144 34062.685128\n",
      "62 41301912 7733678 0.300592484154 0.314496031124 34049.6715614\n",
      "63 41294912 7730301 0.300517547215 0.314738364384 34043.3129254\n",
      "64 41289011 7729342 0.301393412313 0.314735421421 34035.3564468\n",
      "65 41270761 7726896 0.302201771001 0.315089618983 34028.2365443\n",
      "66 41264758 7726243 0.302341061268 0.314789816804 34017.914596\n",
      "67 41253287 7725360 0.302641596067 0.315006685308 34010.7022209\n",
      "68 41239525 7723050 0.301584309644 0.314430887027 33999.1511331\n",
      "69 41236420 7723218 0.301543519052 0.314361603895 33981.6807936\n",
      "70 41230448 7723581 0.301920875899 0.313956829863 33977.6848266\n",
      "71 41228031 7723884 0.302108334631 0.314368976822 33963.6985187\n",
      "72 41222662 7724045 0.302286153522 0.315271020362 33958.8530028\n",
      "73 41214848 7722718 0.302338476382 0.315011815997 33954.4898166\n",
      "74 41210549 7722543 0.302310925118 0.315675562175 33947.838129\n",
      "75 41197389 7721206 0.302155428901 0.315379978487 33942.6798131\n",
      "76 41193458 7721215 0.30233278571 0.314464800652 33931.8658079\n",
      "77 41186968 7720534 0.302613152497 0.314245306429 33929.4874068\n",
      "78 41183943 7720889 0.30293979793 0.31444635894 33917.6093312\n",
      "79 41181709 7720836 0.302987864854 0.315271530763 33914.4078739\n",
      "80 41175769 7720368 0.303277924372 0.316099258106 33911.3049677\n",
      "81 41171433 7720033 0.303099379912 0.316286195279 33905.9777935\n",
      "82 41168241 7720092 0.303230568024 0.316476438851 33901.7991738\n",
      "83 41160421 7720043 0.303086595106 0.316553504507 33896.9318057\n",
      "84 41147767 7717551 0.302912730628 0.315884329905 33889.7366436\n",
      "85 41145036 7717914 0.303258694221 0.316004844805 33878.5120697\n",
      "86 41141831 7717613 0.303787940629 0.316588498038 33875.3378496\n",
      "87 41137964 7717567 0.303626905277 0.316758381984 33871.7681608\n",
      "88 41129873 7716859 0.304035991643 0.316947746307 33867.3955032\n",
      "89 41124668 7715647 0.304381860851 0.31717706215 33860.5133493\n",
      "90 41121094 7715177 0.304780178648 0.317262348846 33851.0935348\n",
      "91 41112267 7714458 0.304765470724 0.31733879332 33846.6884007\n",
      "92 41097707 7714088 0.304702393214 0.317735083902 33837.8719026\n",
      "93 41094132 7713514 0.304982925509 0.318161059176 33815.0482454\n",
      "94 41082506 7711511 0.304848876493 0.318160919961 33810.3791324\n",
      "95 41078739 7711345 0.304820536055 0.317657529981 33797.3312883\n",
      "96 41077072 7711361 0.305220743838 0.317658097753 33791.908427\n",
      "97 41073809 7710343 0.305234797836 0.317770608008 33786.1362557\n",
      "98 41064221 7710466 0.304741455824 0.317737189815 33782.2612297\n",
      "99 41052633 7709027 0.305298577061 0.317665144312 33773.002508\n",
      "100 41042685 7708298 0.305608104182 0.316173139066 33765.8563731\n",
      "101 41015172 7706953 0.306504179698 0.317202951748 33757.3061372\n",
      "102 41007646 7706270 0.306431096379 0.317063085752 33740.3397742\n",
      "103 40999218 7703273 0.306694239001 0.318548074139 33731.5928787\n",
      "104 40994273 7703055 0.306884300526 0.318403383021 33724.6650002\n",
      "105 40992746 7702995 0.30839538062 0.318351855017 33719.4126834\n",
      "106 40990078 7702921 0.308648361953 0.318283039718 33714.1884906\n",
      "107 40987005 7702975 0.308641590383 0.317696278171 33711.9210239\n",
      "108 40981481 7703369 0.30855048448 0.318581174204 33710.8806939\n",
      "109 40971356 7702496 0.30878647891 0.318834143881 33704.8302219\n",
      "110 40968495 7702702 0.308691769864 0.318846319433 33697.3542339\n",
      "111 40959762 7701831 0.308398504819 0.318885662406 33695.0532917\n",
      "112 40957161 7701514 0.307718460367 0.319222989755 33688.7477334\n",
      "113 40948283 7701265 0.30807138003 0.318600934365 33685.9698533\n",
      "114 40936715 7701150 0.308780315843 0.317647955633 33681.7739991\n",
      "115 40928702 7700802 0.308327862432 0.319240748268 33668.4381157\n",
      "116 40924041 7700168 0.308933636575 0.318028983342 33656.4175257\n",
      "117 40918970 7700009 0.308972768031 0.318283162206 33650.5616771\n",
      "118 40915745 7699916 0.308898365235 0.318785024349 33639.5543444\n",
      "119 40911601 7700032 0.308547934758 0.318476350128 33635.8237036\n",
      "120 40908761 7700034 0.308765143691 0.318263206745 33631.0922645\n",
      "121 40905804 7699889 0.309077341711 0.318614338471 33627.446127\n",
      "122 40903188 7700061 0.309026709552 0.318642482553 33624.2256355\n",
      "123 40897333 7699587 0.309515276081 0.318896117698 33621.4664005\n",
      "124 40892712 7699908 0.309313449859 0.318805998715 33616.8235601\n",
      "125 40891186 7700162 0.309381266581 0.318590410967 33611.9771069\n",
      "126 40887921 7699970 0.309700082907 0.319289341464 33610.4332123\n",
      "127 40874600 7700790 0.30914317936 0.319088147763 33606.0186526\n",
      "128 40865748 7700341 0.30945937038 0.319365410606 33593.6396326\n",
      "129 40861894 7700005 0.309449002751 0.319676275192 33587.0894434\n",
      "130 40852399 7699198 0.309309414019 0.319524832295 33582.6972237\n",
      "131 40848231 7699144 0.309357176607 0.319533276867 33570.8548505\n",
      "132 40844469 7699732 0.309254599745 0.31933802497 33567.2450393\n",
      "133 40838671 7699375 0.309625518559 0.320042098453 33563.4831483\n",
      "134 40834563 7699400 0.310032830351 0.319526798617 33553.1850168\n",
      "135 40831521 7699490 0.31043899386 0.319018720819 33550.4094195\n",
      "136 40828602 7699824 0.310360941977 0.319018720819 33548.2906726\n",
      "137 40819706 7699256 0.310753262644 0.320265071053 33545.4233396\n",
      "138 40810464 7698716 0.310355733696 0.320178877427 33533.9782985\n",
      "139 40805697 7697309 0.310319176818 0.320794514855 33525.6968565\n",
      "140 40795138 7695250 0.310691536585 0.321053335598 33512.2621849\n",
      "141 40785629 7694738 0.310578958837 0.320693958611 33503.6006102\n",
      "142 40781329 7694327 0.310904952729 0.3201163694 33496.5290373\n",
      "143 40776884 7694553 0.311303253464 0.320415456771 33491.7402283\n",
      "144 40773493 7694806 0.31134680051 0.320216387243 33490.7897132\n",
      "145 40766875 7694170 0.311276845353 0.320433323266 33486.8505872\n",
      "146 40765034 7694190 0.311200170586 0.320031122416 33481.4968269\n",
      "147 40758487 7694535 0.310976901862 0.320226885803 33479.3156163\n",
      "148 40748620 7693977 0.310544131335 0.320268496174 33474.7502838\n",
      "149 40742583 7693182 0.310674034314 0.320152967957 33468.8092898\n",
      "150 40736993 7692585 0.310218135249 0.319571933208 33460.6732848\n",
      "151 40731477 7692572 0.310498426848 0.319814335732 33454.6762388\n",
      "152 40729482 7692058 0.310948645774 0.319874856117 33448.3072436\n",
      "153 40722580 7691690 0.310649099965 0.319503590436 33445.3351379\n",
      "154 40720922 7691807 0.310874534002 0.320022902596 33438.1788969\n",
      "155 40720396 7692019 0.310838569947 0.320136590137 33435.7767166\n",
      "156 40714382 7691898 0.310886174736 0.319749177334 33433.7251688\n",
      "157 40708973 7692428 0.310601483535 0.319706350509 33429.2257541\n",
      "158 40704296 7692318 0.310635597908 0.319781209486 33423.3398506\n",
      "159 40693910 7691538 0.310795759458 0.319697111104 33417.6705529\n",
      "160 40686637 7691125 0.310904515575 0.319900424125 33409.1098705\n",
      "161 40679879 7690440 0.310963961883 0.320252890924 33395.8031318\n",
      "162 40678572 7690448 0.310907014154 0.32026929732 33387.1511575\n",
      "163 40676030 7690486 0.310960867375 0.320848175318 33385.4393339\n",
      "164 40673910 7690542 0.310975728777 0.320857638495 33380.1725022\n",
      "165 40672108 7690684 0.311002385885 0.320434804221 33377.7594338\n",
      "166 40666472 7690440 0.310872630029 0.319781500794 33375.6805997\n",
      "167 40661546 7690181 0.310993411973 0.320435586806 33373.4178805\n",
      "168 40655703 7689533 0.310902567618 0.320342580205 33367.4333422\n",
      "169 40644337 7688233 0.311333709185 0.321124157736 33360.8452495\n",
      "170 40633098 7686694 0.312953604582 0.320745503764 33347.9059801\n",
      "171 40632437 7686666 0.312868309983 0.320758197609 33337.3656822\n",
      "172 40630907 7686606 0.31297378995 0.321174505886 33336.8081826\n",
      "173 40628871 7686634 0.312856467139 0.321653155131 33334.9422012\n",
      "174 40627253 7686625 0.312719063041 0.321759312638 33333.0302274\n",
      "175 40623566 7686518 0.312667185915 0.320750245472 33331.2043441\n",
      "176 40621421 7686438 0.312795513829 0.32061196274 33327.1852279\n",
      "177 40616641 7685947 0.312937972796 0.321165543885 33323.8816249\n",
      "178 40616347 7685981 0.312947203599 0.321155014923 33317.1676342\n",
      "179 40614698 7685744 0.313084364601 0.320764563767 33315.7896366\n",
      "180 40613458 7685830 0.313078782444 0.320764563767 33314.3120085\n",
      "181 40607977 7686128 0.313039629645 0.320197891721 33312.6535889\n",
      "182 40602905 7685674 0.312955103027 0.320242683939 33310.082456\n",
      "183 40601435 7685800 0.313077788464 0.320241618663 33305.6727386\n",
      "184 40600361 7685753 0.313142318813 0.320403118386 33303.3743235\n",
      "185 40596587 7685632 0.313171977716 0.320013681003 33301.7840918\n",
      "186 40594587 7685702 0.313129430651 0.320000437968 33296.9415469\n",
      "187 40588787 7684925 0.313415997037 0.321831084738 33295.0125359\n",
      "188 40579283 7683701 0.313505918441 0.321969250915 33290.4247464\n",
      "189 40573753 7682628 0.313564475136 0.322099610284 33281.5869375\n",
      "190 40569282 7682809 0.31301779152 0.320665223068 33276.3894289\n",
      "191 40561343 7682738 0.312928092735 0.320209966033 33269.4997471\n",
      "192 40553582 7683195 0.313088929079 0.321656222623 33266.5881103\n",
      "193 40548339 7683024 0.313118667143 0.321845410969 33260.3502083\n",
      "194 40545346 7682824 0.313260985486 0.322200478913 33254.5038081\n",
      "195 40543031 7683214 0.313280894805 0.322078260907 33250.3097571\n",
      "196 40538751 7683008 0.313239556722 0.322274811483 33247.9134817\n",
      "197 40537943 7683404 0.313370818837 0.322207530414 33241.1536354\n",
      "198 40535325 7683966 0.313412582344 0.321876649035 33239.6289377\n",
      "199 40529253 7682840 0.313354667566 0.322592653943 33237.1369139\n",
      "200 40528511 7682878 0.313387112503 0.322316258785 33230.2683744\n",
      "201 40521769 7683000 0.313433742675 0.322375522106 33228.4382461\n",
      "202 40514911 7683395 0.313313148334 0.322377153731 33216.6665096\n",
      "203 40503887 7682647 0.313322454658 0.32239874265 33205.0772627\n",
      "204 40499573 7683024 0.31339700873 0.321952044549 33198.7926806\n",
      "205 40494561 7682918 0.313188765144 0.321834168916 33195.9131192\n",
      "206 40491790 7682317 0.313363165507 0.32256430947 33189.4321698\n",
      "207 40489325 7681962 0.31359136053 0.323000045615 33185.3992972\n",
      "208 40485280 7681146 0.314091125783 0.322153995436 33176.8617461\n",
      "209 40480349 7681418 0.314035576628 0.322600076312 33174.1272111\n",
      "210 40478128 7680950 0.313979960397 0.32250888485 33168.4294548\n",
      "211 40473115 7679616 0.314153027235 0.322721765218 33165.7105258\n",
      "212 40465999 7678284 0.314341080424 0.321969492656 33160.9093245\n",
      "213 40463236 7678331 0.314330604202 0.321922419407 33154.2725231\n",
      "214 40459830 7678496 0.314334092114 0.321570305508 33150.5315563\n",
      "215 40457529 7678516 0.314447556553 0.321760444347 33143.2581039\n",
      "216 40451567 7678869 0.314741695964 0.320444363427 33142.0565179\n",
      "217 40444885 7677930 0.314812314938 0.321093996231 33136.1541041\n",
      "218 40436909 7677384 0.314958431372 0.321306245504 33131.0696674\n",
      "219 40430932 7677517 0.315258815334 0.321086167213 33120.0862511\n",
      "220 40425377 7677059 0.315344724044 0.320824589499 33114.8734198\n",
      "221 40417593 7676874 0.315161684905 0.321476703042 33106.1175715\n",
      "222 40412770 7676496 0.315175767873 0.321593596148 33096.6900047\n",
      "223 40408265 7676553 0.314920996524 0.321297392314 33091.4393043\n",
      "224 40405718 7676339 0.315424425515 0.322565504223 33086.2789284\n",
      "225 40404104 7676423 0.316054258533 0.322404863817 33082.2185488\n",
      "226 40399532 7676155 0.316221792401 0.322363580423 33080.7109762\n",
      "227 40393481 7676193 0.316152870093 0.322234718407 33075.2076598\n",
      "228 40388122 7676047 0.316213801703 0.322334192729 33070.6583918\n",
      "229 40382670 7676539 0.316337910811 0.32223278095 33066.6782042\n",
      "230 40380095 7676378 0.316340301857 0.322829781555 33061.1709159\n",
      "231 40375447 7675746 0.316359751061 0.322239231737 33058.9913816\n",
      "232 40372989 7675916 0.316273405969 0.322206681745 33054.0029408\n",
      "233 40371159 7675510 0.316559241054 0.322131444406 33049.3597938\n",
      "234 40367485 7675296 0.316760547079 0.321675733941 33046.5752241\n",
      "235 40364342 7675348 0.316989844379 0.321896246604 33040.1031973\n",
      "236 40359535 7675182 0.316958348682 0.321601038461 33036.5876816\n",
      "237 40358877 7675178 0.317056157604 0.321489857564 33033.8607051\n",
      "238 40355111 7675368 0.317275422128 0.321505248366 33032.6149666\n",
      "239 40346000 7675304 0.317304280581 0.321525080905 33030.4382885\n",
      "240 40341029 7676076 0.317253773848 0.32151923313 33024.0242093\n",
      "241 40337695 7675942 0.317052922364 0.321317967458 33021.1724675\n",
      "242 40331591 7676041 0.31741358027 0.32213233861 33018.8517074\n",
      "243 40325802 7676063 0.31753273207 0.322314614356 33013.5255776\n",
      "244 40319260 7675817 0.31744792413 0.322553590504 33006.4123895\n",
      "245 40313035 7675542 0.316990023389 0.322343731857 32997.3238168\n",
      "246 40311687 7675522 0.316992206159 0.322542335426 32993.7941996\n",
      "247 40309851 7675822 0.316834015599 0.322524237958 32992.5891822\n",
      "248 40308866 7675576 0.316896187815 0.322717423805 32990.7145012\n",
      "249 40305552 7675965 0.316768649666 0.322823398257 32989.1697054\n",
      "250 40303018 7675825 0.316897004641 0.322823532765 32986.2208786\n",
      "251 40301137 7675624 0.317084088363 0.32260433223 32983.8729297\n",
      "252 40300427 7675262 0.317125398778 0.322607203016 32982.2042552\n",
      "253 40300051 7675272 0.317144466448 0.322607203016 32981.1985566\n",
      "254 40299765 7675298 0.317186905687 0.32256465998 32980.6682769\n",
      "255 40299693 7675278 0.317344122734 0.32256465998 32980.1925224\n",
      "256 40296530 7674932 0.317336060914 0.322243874392 32979.6297779\n",
      "257 40289078 7674985 0.31767894585 0.321996405398 32976.0812837\n",
      "258 40284918 7674849 0.317089482717 0.321551546193 32965.4446758\n",
      "259 40281115 7674647 0.317014265451 0.321486515063 32959.8039192\n",
      "260 40279916 7674788 0.31707751843 0.321804602509 32951.5041591\n",
      "261 40267745 7674230 0.316666857984 0.322501355566 32950.5004347\n",
      "262 40263639 7674394 0.31679242622 0.322398516561 32944.1226915\n",
      "263 40255860 7673937 0.316893714347 0.321437100167 32940.5474763\n",
      "264 40253665 7673701 0.316635465288 0.320949405662 32935.2712074\n",
      "265 40251214 7672618 0.31690386981 0.321193793613 32933.0457467\n",
      "266 40244929 7672325 0.316369628911 0.321301276199 32925.674825\n",
      "267 40241258 7671792 0.31676727425 0.321323295728 32920.9017575\n",
      "268 40236473 7671810 0.317179493822 0.321501608113 32915.7276927\n",
      "269 40231223 7671794 0.317357927176 0.321606931239 32911.8352393\n",
      "270 40221094 7670651 0.317396224014 0.321677223571 32905.6354389\n",
      "271 40215399 7669774 0.317302078458 0.321553005324 32894.3067192\n",
      "272 40213394 7669672 0.317469712689 0.321142065388 32888.3545088\n",
      "273 40209053 7668867 0.317612318056 0.320857293775 32885.8023435\n",
      "274 40204649 7669047 0.317713768497 0.321072150338 32879.8920177\n",
      "275 40201658 7669261 0.317760638983 0.321279059444 32875.958099\n",
      "276 40199904 7669259 0.317842471086 0.321236655084 32872.7857097\n",
      "277 40199518 7669303 0.317801431017 0.321286061609 32871.2353559\n",
      "278 40197187 7669109 0.317729877703 0.321832920404 32871.2631071\n",
      "279 40196484 7669143 0.317680375664 0.321633527352 32869.490614\n",
      "280 40190000 7668863 0.318801581865 0.321953326388 32868.9413026\n",
      "281 40182322 7668584 0.318730014325 0.322120499502 32860.3581416\n",
      "282 40180762 7668704 0.318741937753 0.322126518543 32850.5711994\n",
      "283 40177186 7668608 0.318772838786 0.321806066179 32849.7439138\n",
      "284 40176274 7668522 0.318876085869 0.322020103536 32846.6494021\n",
      "285 40173724 7668426 0.318865383181 0.322031351767 32845.8954185\n",
      "286 40170845 7667853 0.318870223255 0.321407141498 32842.5414661\n",
      "287 40169919 7667823 0.318898699622 0.321407141498 32840.8221373\n",
      "288 40169065 7667881 0.318907435639 0.321316834373 32839.4575823\n",
      "289 40167756 7667625 0.319002366767 0.321304893488 32838.9199092\n",
      "290 40166169 7667667 0.319071448752 0.320924340394 32837.5885838\n",
      "291 40162781 7667177 0.319296130832 0.321615501199 32836.7254428\n",
      "292 40160479 7667229 0.31949916775 0.321622149407 32830.8439662\n",
      "293 40157991 7667162 0.319468147762 0.32175761487 32824.8475901\n",
      "294 40154713 7667973 0.319676460782 0.321583825645 32822.7171068\n",
      "295 40152061 7667759 0.320004662715 0.322589464577 32817.8333065\n",
      "296 40149641 7667677 0.319933370234 0.322809079269 32815.9677149\n",
      "297 40147101 7667975 0.319902696873 0.322779140144 32813.3749993\n",
      "298 40142420 7667751 0.319795577231 0.322947977435 32811.7535123\n",
      "299 40138696 7667401 0.319673494983 0.322997005784 32805.7982336\n"
     ]
    }
   ],
   "source": [
    "estimator = LambdaRank(learning_rate=0.01, n_estimators=300, sigma=1, start_depth=3)\n",
    "estimator.fit(DATA=rowData, persent_valid=0.2, normalize=relNormalize2, T_NDCG=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testRow  = DataFrame.from_csv(\"../data/testset.cvs\", index_col=False).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = estimator.predict(testRow[:, 1:-1])\n",
    "saveResults(testRow[:, -1], ans, \"result13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

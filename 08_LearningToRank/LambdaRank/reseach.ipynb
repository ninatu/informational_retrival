{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант 1 (Деревья). Нерабочий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPath = \"../data/train.data.cvs\"\n",
    "rowData = DataFrame.from_csv(trainPath, index_col=False).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relNormalize(rel, max_rel=20):\n",
    "    norm_rel = rel - min(rel)\n",
    "    if max(norm_rel) != 0:\n",
    "        norm_rel = norm_rel * max_rel / max(norm_rel)\n",
    "    return norm_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QueryData:\n",
    "    def __init__(self, X, rel, T_NDCG=5):\n",
    "        self._X = np.copy(X)\n",
    "        self._n = self._X.shape[0]\n",
    "        self._rel = np.copy(rel)\n",
    "        self._T_NDCG = T_NDCG\n",
    "        self._predcomputeNDCG()\n",
    "        \n",
    "    def _predcomputeNDCG(self):        \n",
    "        right_order = np.argsort(self._rel)[::-1]\n",
    "        self._X = self._X[right_order]    \n",
    "        self._rel = self._rel[right_order]\n",
    "        self._2_rel = 2 ** self._rel - 1   \n",
    "        log2_order = np.log2(np.array(range(self._n)) + 2)\n",
    "        self._max_DCG = sum(self._2_rel[:self._T_NDCG] / log2_order[:self._T_NDCG])\n",
    "   \n",
    "    def getX(self):\n",
    "        return self._X\n",
    "    \n",
    "    def getY(self):\n",
    "        return self._rel\n",
    "        \n",
    "    def getSwapNDCGMatrix(self, rel):\n",
    "        order = np.array(np.argsort(rel)[::-1]) + 1\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        matr_elem_DCG = np.tile(elem_DCG, (self._n, 1))\n",
    "        matr_swap_elem_DCG = self._2_rel.reshape((self._n, 1)) / log2_order.reshape((1, self._n)) \n",
    "        \n",
    "        DCG = sum(elem_DCG[order <= self._T_NDCG])        \n",
    "        lambda_mtr = np.full((self._n, self._n), DCG)\n",
    "        lambda_mtr = lambda_mtr - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "        no_null_swap = ((order <= self._T_NDCG).reshape((self._n, 1)) + (order <= self._T_NDCG).reshape((1, self._n))) > 0 \n",
    "        lambda_mtr = lambda_mtr * no_null_swap\n",
    "        if self._max_DCG != 0:\n",
    "            return lambda_mtr / self._max_DCG\n",
    "        else:\n",
    "            return lambda_mtr\n",
    "    \n",
    "    def getNDCG(self, rel):\n",
    "        order = np.array(np.argsort(rel)[::-1]) + 1\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        DCG = sum(elem_DCG[order <= self._T_NDCG])\n",
    "        if self._max_DCG != 0:\n",
    "            return DCG / self._max_DCG\n",
    "        else:\n",
    "            return DCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryData:\n",
    "    def __init__(self, X, rel):\n",
    "        uniq_rel = np.unique(rel)\n",
    "        self._X = np.empty((uniq_rel.shape[0], X.shape[1]))\n",
    "        self._rel = np.empty(uniq_rel.shape[0])\n",
    "        for i, val in enumerate(uniq_rel):\n",
    "            self._X[i] = (X[rel == val])[0]\n",
    "            self._rel[i] = (rel[rel == val])[0]\n",
    "            \n",
    "        #self._X = np.copy(X)\n",
    "        self._n = self._X.shape[0]\n",
    "        #self._rel = np.copy(rel)\n",
    "        \n",
    "        self._right_order = np.argsort(self._rel)[::-1]\n",
    "        self._2_rel = 2 ** self._rel[self._right_order] - 1   \n",
    "        self._log2_order = np.log2(np.array(range(self._n)) + 2)\n",
    "        \n",
    "    def maxDCG(self, T_NDCG=5):        \n",
    "        return sum(self._2_rel[:T_NDCG] / self._log2_order[:T_NDCG])\n",
    "   \n",
    "    def getX(self):\n",
    "        return self._X\n",
    "    \n",
    "    def getY(self):\n",
    "        return self._rel\n",
    "        \n",
    "    def getSwapNDCGMatrix(self, rel, T_NDCG):\n",
    "        rel = rel[self._right_order]\n",
    "        order = np.array(np.argsort(rel)[::-1]) + 1\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        matr_elem_DCG = np.tile(elem_DCG, (self._n, 1))\n",
    "        matr_swap_elem_DCG = self._2_rel.reshape((self._n, 1)) / log2_order.reshape((1, self._n)) \n",
    "        \n",
    "        DCG = sum(elem_DCG[order <= T_NDCG])        \n",
    "        lambda_mtr = np.full((self._n, self._n), DCG)\n",
    "        lambda_mtr = lambda_mtr - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "        no_null_swap = ((order <= T_NDCG).reshape((self._n, 1)) + (order <= T_NDCG).reshape((1, self._n))) > 0 \n",
    "        lambda_mtr = lambda_mtr * no_null_swap\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG != 0:\n",
    "            return lambda_mtr / max_DCG \n",
    "        else:\n",
    "            return lambda_mtr\n",
    "    \n",
    "    def getNDCG(self, rel, T_NDCG):\n",
    "        rel = rel[self._right_order]\n",
    "        order = np.array(np.argsort(rel)[::-1]) + 1\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        DCG = sum(elem_DCG[order <= T_NDCG])\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG  != 0:\n",
    "            return DCG / max_DCG\n",
    "        else:\n",
    "            return DCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries = rowData[:, -1]\n",
    "uniq_queries = np.unique(queries)\n",
    "queries_train_data = []\n",
    "for q in uniq_queries:\n",
    "    xy = rowData[queries == q][:, :-1]\n",
    "    queries_train_data.append(QueryData(xy[:, 1:], relNormalize(xy[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save 1/5 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nina/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "queries = rowData[:, -1]\n",
    "uniq_queries = np.unique(queries)\n",
    "random.shuffle(uniq_queries)\n",
    "small_queries = uniq_queries[: uniq_queries.shape[0] / 5]\n",
    "filter_for_queries = np.sum((queries == x for x in small_queries)) > 0\n",
    "rowData2 = rowData[filter_for_queries]\n",
    "np.save(\"small_train\", rowData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "\n",
    "class LambdaRankTrees :\n",
    "    def __init__ (self, learning_rate= 1, n_estimators=100, sigma=1, start_depth=6) :\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = None\n",
    "        \n",
    "    def _getTrainX(self, queries_data):\n",
    "        n = 0\n",
    "        m = queries_data[0].getX().shape[1]\n",
    "        for query_data in queries_data:\n",
    "            n += query_data._n\n",
    "            \n",
    "        X = np.empty((n, m), dtype=np.float64)\n",
    "        indexs = []\n",
    "        cur_index = 0\n",
    "        for query_data in queries_data:\n",
    "            cur_n = query_data._n\n",
    "            X[cur_index:cur_index + cur_n] = query_data.getX()\n",
    "            indexs.append(range(cur_index,cur_index + cur_n))\n",
    "            cur_index += cur_n            \n",
    "        return X, indexs\n",
    "    \n",
    "    def _getGradient(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        g = np.empty(h.shape[0], dtype=np.float64)\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            rel_n = rel.shape[0]\n",
    "            lambda_matr = -self._sigma / (1 + np.exp(rel.reshape((rel_n, 1)) - rel.reshape((1, rel_n)))) * query_data.getSwapNDCGMatrix(rel, T_NDCG)\n",
    "            tril = np.tril(lambda_matr, k=-1)\n",
    "            lambda_vector =  np.sum(tril, axis=0) - np.sum(tril.T, axis=0)\n",
    "            g[indexs] = lambda_vector\n",
    "        return g\n",
    "    \n",
    "    def _getNDCG(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        ndcg = 0\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            ndcg+= query_data.getNDCG(rel, T_NDCG)\n",
    "        return ndcg / len(indexs_data)\n",
    "    \n",
    "    def fit(self, queries_data, max_add_iteration=10, persent_valid=0.4) :\n",
    "        random.shuffle(queries_data)        \n",
    "        count_valid = int(persent_valid * len(queries_data))\n",
    "        data_valid = queries_data[:count_valid]\n",
    "        data_train = queries_data[count_valid:]\n",
    "        \n",
    "        X_train, index_train = self._getTrainX(data_train)\n",
    "        X_valid, index_valid = self._getTrainX(data_valid)\n",
    "        \n",
    "        self._trees = []\n",
    "        #d_tree = DT(max_depth=self._start_depth)\n",
    "        #d_tree.fit(X_train, np.zeros(X_train.shape[0]))        \n",
    "        #self._trees.append(d_tree)\n",
    "        h_train = np.zeros(X_train.shape[0]) #d_tree.predict(X_train) * self._learning_rate   \n",
    "        h_valid = np.zeros(X_valid.shape[0])# d_tree.predict(X_valid) * self._learning_rate \n",
    "        \n",
    "        for iteration in range(self._n_estimators - 1) :\n",
    "            g = self._getGradient(data_train, h_train, index_train, 200)\n",
    "            norm_g = np.linalg.norm(g)            \n",
    "            \"\"\"\n",
    "            if norm_g > 3 :\n",
    "                d_tree = dt.DecisionTree('mse', self.max_depth, collect_gains_features=self.collect_gains_features)\n",
    "            else :\n",
    "                d_tree = dt.DecisionTree('mse', 3 * self.max_depth, collect_gains_features=self.collect_gains_features)\n",
    "            \"\"\"\n",
    "            #data = np.hstack((x, g.reshape(N, 1)))\n",
    "            d_tree = DT(max_depth=self._start_depth)\n",
    "            d_tree.fit(X_train, -g)\n",
    "            self._trees.append(d_tree)\n",
    "            h_train += self._learning_rate * d_tree.predict(X_train)\n",
    "            h_valid += self._learning_rate * d_tree.predict(X_valid)\n",
    "            \n",
    "            print(iteration, self._getNDCG(data_train, h_train, index_train, 200), \n",
    "                  self._getNDCG(data_valid, h_valid, index_valid, 200),\n",
    "                  self._getNDCG(data_train, h_train, index_train, 5),\n",
    "                  self._getNDCG(data_valid, h_valid, index_valid, 5),\n",
    "                  min(g), max(g), norm_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.497820015453 0.493057026561 0.486061325237 0.479736631324 -2.14857107211 1.82708231185 73.7833373181\n",
      "1 0.497820007461 0.493073221956 0.486061317244 0.479736613523 -3.46779615142 2.88473461137 116.339052056\n",
      "2 0.497820007461 0.493073239755 0.486061317244 0.479736631324 -4.02074875303 3.34028318043 139.598143368\n",
      "3 0.497819330594 0.493072423385 0.486060640377 0.47973577421 -4.11171509198 3.44589787724 145.437299392\n",
      "4 0.497819330594 0.493072642521 0.486060640377 0.47973577421 -4.12811386045 3.47669901588 146.849519973\n",
      "5 0.497819330594 0.49305579834 0.486060640377 0.479735245818 -4.13180070864 3.48749962038 147.25210405\n",
      "6 0.497819330594 0.493056326731 0.486060640377 0.47973577421 -4.13273868287 3.49155727026 147.385395035\n",
      "7 0.497819330594 0.493056326731 0.486060640377 0.47973577421 -4.13299198138 3.49312705513 147.435256997\n",
      "8 0.497819330594 0.493056326731 0.486060640377 0.47973577421 -4.13306225311 3.49374410563 147.456091755\n",
      "9 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308197934 3.49398893488 147.465677123\n",
      "10 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308754491 3.49408660031 147.470457569\n",
      "11 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330891186 3.49412567618 147.473002394\n",
      "12 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308956398 3.49414133512 147.474429204\n",
      "13 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308969008 3.49414761522 147.475263314\n",
      "14 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308972579 3.49415013488 147.475768544\n",
      "15 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.13308973591 3.49415114597 147.476084801\n",
      "16 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.13308973877 3.49415155173 147.476289553\n",
      "17 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.13308973958 3.49415171456 147.476427157\n",
      "18 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.13308973981 3.4941517799 147.47652367\n",
      "19 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.13308973988 3.49415180613 147.4765947\n",
      "20 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.49415181665 147.476649728\n",
      "21 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.49415182087 147.476694578\n",
      "22 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182257 147.476732852\n",
      "23 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182325 147.476766787\n",
      "24 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182352 147.476797772\n",
      "25 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182363 147.47682667\n",
      "26 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182367 147.476854009\n",
      "27 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.49415182369 147.476880111\n",
      "28 0.497819330594 0.493056107594 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.476905166\n",
      "29 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.476929285\n",
      "30 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.476952528\n",
      "31 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.476974925\n",
      "32 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.476996489\n",
      "33 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.477017227\n",
      "34 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.47703714\n",
      "35 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.477056229\n",
      "36 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.477074498\n",
      "37 0.497819330594 0.493056144375 0.486060640377 0.47973577421 -4.1330897399 3.4941518237 147.477091951\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d04aa8d07ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambdaRank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaRankTrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlambdaRank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fa64b3770da6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, queries_data, max_add_iteration, persent_valid)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mh_valid\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             print(iteration, self._getNDCG(data_train, h_train, index_train, 200), \n\u001b[0m\u001b[1;32m     80\u001b[0m                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fa64b3770da6>\u001b[0m in \u001b[0;36m_getNDCG\u001b[0;34m(self, queries_data, h, indexs_data, T_NDCG)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mquery_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mndcg\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mquery_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_NDCG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mndcg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexs_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3399dee5f0a1>\u001b[0m in \u001b[0;36mgetNDCG\u001b[0;34m(self, rel, T_NDCG)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlog2_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0melem_DCG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_2_rel\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlog2_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mDCG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_DCG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mT_NDCG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mmax_DCG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_NDCG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_DCG\u001b[0m  \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdaRank = LambdaRankTrees()\n",
    "lambdaRank.fit(queries_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "\n",
    "    def predict(self, x) :\n",
    "        y = np.zeros(x.shape[0])\n",
    "        for tree in self.trees:\n",
    "            y = y + self.learning_rate * tree.predict(x)\n",
    "\n",
    "        return np.apply_along_axis(lambda x: (1.0 / (1 + np.exp(-x)) > 0.5) * 1.0, 0, y)\n",
    "\n",
    "    def score(self, x, y) :\n",
    "        h = np.zeros(x.shape[0])\n",
    "        score_y = []\n",
    "        for tree in self.trees:\n",
    "            h = h + self.learning_rate * tree.predict(x)\n",
    "            y_pred = np.apply_along_axis(lambda x: (1.0 / (1 + np.exp(-x)) > 0.5) * 1.0, 0, h)\n",
    "            score_y.append(accuracy_score(y, y_pred))\n",
    "        return np.array(score_y)\n",
    "        \n",
    "    def f1_score(self, x, y) :\n",
    "        h = np.zeros(x.shape[0])\n",
    "        score_y = []\n",
    "        for tree in self.trees:\n",
    "            h = h + self.learning_rate * tree.predict(x)\n",
    "            y_pred = np.apply_along_axis(lambda x: (1.0 / (1 + np.exp(-x)) > 0.5) * 1.0, 0, h)\n",
    "            score_y.append(f1_score(y, y_pred))\n",
    "        return np.array(score_y)\n",
    "        \n",
    "    def f1_macro(self, x, y) :\n",
    "        h = np.zeros(x.shape[0])\n",
    "        score_y = []\n",
    "        score_y1 = []\n",
    "        score_y2 = []\n",
    "        for tree in self.trees:\n",
    "            h = h + self.learning_rate * tree.predict(x)\n",
    "            y_pred = np.apply_along_axis(lambda x: (1.0 / (1 + np.exp(-x)) > 0.5) * 1.0, 0, h)\n",
    "            labels = unique_labels(y, y_pred)\n",
    "            f1 = f1_score(y, y_pred, labels=labels, average=None)\n",
    "            f1_macro = 0\n",
    "            for i, label in enumerate(labels):\n",
    "                f1_macro += f1[i]    \n",
    "            score_y1.append(f1[0])\n",
    "            score_y2.append(f1[1])\n",
    "            score_y.append(f1_macro)\n",
    "        return np.array(score_y)/ 2.0, np.array(score_y1), np.array(score_y2)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант 2 с нейросетями (недоделанный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from operator import add, mul, sub\n",
    "from math import exp, ceil, log\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2grey\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaRankEstimator:\n",
    "    def __init__(self) :\n",
    "        pass\n",
    "    def init(self, count_input, count_layers=1, act_funcs=None, der_act_func=None,\n",
    "             count_neurals_layer=None, learning_rate=0.1, shuffle = True) :\n",
    "        defalt_count_neural = 10\n",
    "        if count_neurals_layer is None:\n",
    "            count_neurals_layer = []\n",
    "            for l in range(count_layers):\n",
    "                count_neurals_layer.append(defalt_count_neural)\n",
    "        if act_funcs is not None :\n",
    "            self.act_funcs = act_funcs\n",
    "            self.der_act_func = der_act_func\n",
    "        else :   \n",
    "            self.act_funcs = []\n",
    "            self.der_act_func = []\n",
    "            for l in range(count_layers):\n",
    "                self.act_funcs.append(logistic_activation_1) # max_0)\n",
    "                self.der_act_func.append(der_logistic_activation_1) # der_max_0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.count_output = 1\n",
    "        self.shuffle = shuffle\n",
    "        count_neurals_layer.append(self.count_output)\n",
    "        self.act_funcs.append(equal_func)\n",
    "        self.der_act_func.append(equal_func)\n",
    "        #self.function_error = mean_square\n",
    "        #self.dE_dz_last = der_mean_square - надо заменить!!!!!!!!!!!!!!!\n",
    "        self.create_network(count_input, count_layers + 1, count_neurals_layer)\n",
    "        self.initialize()\n",
    "\n",
    "    def fit(self, data, add_step = 3, add_iteration=100, max_epoche=3000, sigma=1,\n",
    "            coeff_R1=0, coeff_R2=0) :\n",
    "        self.coeff_R1 = coeff_R1\n",
    "        self.begin_coeff_R1 = coeff_R1\n",
    "        self.coeff_R2 = coeff_R2\n",
    "        self.begin_coeff_R2 = coeff_R2\n",
    "        self.validation_error = []\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(data)\n",
    "        \n",
    "        count_valid = int(4 * len(data) / 10)\n",
    "        data_valid = data[:count_valid]\n",
    "        data_train = data[count_valid:]\n",
    "\n",
    "        best_error = 1e100\n",
    "        best_weight = None\n",
    "        number_epoche = None\n",
    "        cur_step = 0\n",
    "        current_epoche = 0\n",
    "        while True :\n",
    "            #epoche\n",
    "            random.shuffle(data_train)\n",
    "            epoche_error = 0\n",
    "            for iteration in range(len(data_train)):#range(self.batch_count) :\n",
    "                x = data_train[iteration][:, :-1]\n",
    "                y_true = data_train[iteration][:, -1]\n",
    "                y_pred = self.forward_propogation(x)\n",
    "                print(y_pred.shape, y_true.shape)\n",
    "                break\n",
    "            break\n",
    "\n",
    "            \"\"\"\n",
    "            self.init_add_weight()\n",
    "            error = 0\n",
    "            for j in range(size_batch) :\n",
    "                n = iteration * size_batch + j\n",
    "                answer = self.forward_propogation(data_train[n])\n",
    "                self.back_propogation(data_train[n], answer, y_train[n])\n",
    "                error = error + self.function_error(y_train[n], answer)\n",
    "            self.add_mean_gradient(size_batch)\n",
    "            epoche_error = epoche_error + error\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            epoche_error = epoche_error/ (self.batch_count * size_batch)\n",
    "            print \"Epoche error\", epoche_error, \n",
    "            \n",
    "            error = 0\n",
    "            answer = self._predict_(data_x_valid)\n",
    "            for i, y in enumerate(answer):\n",
    "                error = error + self.function_error(y_valid[i], y)\n",
    "            error = error / answer.shape[0]            \n",
    "            print \"Validation error\", error\n",
    "            \n",
    "            if error <= best_error:\n",
    "              #  print \"New best error\", error\n",
    "                best_error = error\n",
    "                best_weight = self.get_copy_weight(self.weight_network)\n",
    "                self.validation_error.append(error)\n",
    "                number_epoche = current_epoche\n",
    "                \n",
    "            \n",
    "            if  number_epoche + add_iteration <= current_epoche:# and cur_step < add_step:\n",
    "                cur_step = cur_step + 1                \n",
    "                self.weight_network = self.get_copy_weight(best_weight)\n",
    "                self.learning_rate = self.learning_rate / 2.0\n",
    "                number_epoche = current_epoche\n",
    "                print \"New learning rate\", self.learning_rate\n",
    "                if cur_step > add_step:\n",
    "                    self.count_epoche_for_learn = current_epoche - 1\n",
    "                    break\n",
    "            \n",
    "            self.coeff_R1 = self.begin_coeff_R1 / ((current_epoche) ** 3 + 1)\n",
    "            self.coeff_R2 = self.begin_coeff_R2 / ((current_epoche) ** 3 + 1)\n",
    "            for i, x in enumerate(self.KL_probability):\n",
    "                if x is not None:\n",
    "                    prob, coeff = self.KL_begin_probability[i]\n",
    "                    self.KL_probability[i] = (prob, coeff / ((current_epoche) ** 3 + 1))\n",
    "\n",
    "            current_epoche = current_epoche + 1    \n",
    "            if current_epoche > max_epoche:\n",
    "                self.weight_network = self.get_copy_weight(best_weight)\n",
    "                self.count_epoche_for_learn = current_epoche - 1\n",
    "                break\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        \n",
    "    def get_copy_weight(self, weights) :\n",
    "        new_weight = []\n",
    "        for w in weights:\n",
    "            new_weight.append(w.copy())\n",
    "        return new_weight\n",
    "        \n",
    "    def _predict_(self, data) :\n",
    "        y = np.empty((data.shape[0], self.count_output))\n",
    "        for i, x in enumerate(data):\n",
    "            y[i, :] = self.forward_propogation(x)\n",
    "        return y\n",
    "        \n",
    "    def predict(self, data):\n",
    "        y_answer = self._predict_(data)\n",
    "        if self.isClassification:\n",
    "            y_pred = np.empty(y_answer.shape[0])\n",
    "            for i, y in enumerate(y_answer):            \n",
    "                y_pred[i] = self.uniq_label[y.argmax()]\n",
    "            return y_pred        \n",
    "        return y_answer\n",
    "    \n",
    "    def init_add_weight(self) :\n",
    "        self.add_weight = []\n",
    "        for layer in self.weight_network:\n",
    "            self.add_weight.append(np.zeros(layer.shape))\n",
    "\n",
    "    def create_network(self, count_input, count_layers, count_neurals_layer) :\n",
    "        self.weight_network = []\n",
    "        self.KL_probability = []\n",
    "        self.KL_begin_probability = []\n",
    "        count_neurals_layer = count_neurals_layer[:]\n",
    "        count_neurals_layer.insert(0, count_input)    \n",
    "        for l in range(1, count_layers + 1) :\n",
    "            self.weight_network.append(np.zeros((count_neurals_layer[l], count_neurals_layer[l-1])))\n",
    "            self.KL_probability.append(None)\n",
    "            self.KL_begin_probability.append(None)\n",
    "\n",
    "    def initialize(self, mean=0, var=1.0/800) :\n",
    "        for l, layer in enumerate(self.weight_network) :\n",
    "            var = 1.0 / layer.shape[1] #/ 10.0 #* 25\n",
    "            weights = [[random.gauss(mean, var) for i in range(layer.shape[1])] for j in range(layer.shape[0])]\n",
    "            self.weight_network[l] = np.array(weights)\n",
    "\n",
    "    def set_KL_probality(self, layer, prob, coeff):\n",
    "        self.KL_probability[layer] = (prob, coeff)\n",
    "        self.KL_begin_probability[layer] = (prob, coeff)\n",
    "        \n",
    "    def forward_propogation(self, data) :\n",
    "        cur_x = data.T\n",
    "        self.x = []\n",
    "        self.dy_dz = []\n",
    "        self.x.append(cur_x)\n",
    "        for l, weight_matrix in enumerate(self.weight_network):\n",
    "            z = np.dot(weight_matrix, cur_x)\n",
    "            func = (self.act_funcs)[l]\n",
    "            der_func = self.der_act_func[l]\n",
    "            cur_x = func(z)\n",
    "            self.x.append(cur_x)\n",
    "            self.dy_dz.append(der_func(z))\n",
    "        return cur_x\n",
    "        \n",
    "    def back_propogation(self, data, answer, true_y) :\n",
    "        dE_dz = self.dE_dz_last(true_y, answer)        \n",
    "        l = len(self.add_weight)\n",
    "        prev_x = self.x[l - 1]\n",
    "        dE_dz = dE_dz.reshape((dE_dz.shape[0], 1))\n",
    "        prev_x = prev_x.reshape((1, prev_x.shape[0]))\n",
    "        self.add_weight[l - 1] = self.add_weight[l - 1]  + np.dot(dE_dz, prev_x\n",
    "                ) + self.coeff_R1 * sign(self.weight_network[l - 1]\n",
    "                ) + self.coeff_R2 * self.weight_network[l - 1]\n",
    "        for i in range(l - 2, -1, -1):\n",
    "            tmp1_matrix = np.dot(self.weight_network[i+1].T , dE_dz)\n",
    "            prev_x = self.x[i]\n",
    "            prev_x = prev_x.reshape((1, prev_x.shape[0]))\n",
    "            dy_dz = self.dy_dz[i]\n",
    "            dy_dz = dy_dz.reshape((dy_dz.shape[0], 1))\n",
    "            tmp2_matrix = np.dot(dy_dz, prev_x)\n",
    "            add_weight = tmp2_matrix * tmp1_matrix  \n",
    "            add_R1 = self.coeff_R1 * sign(self.weight_network[i]) \n",
    "            add_R2 = self.coeff_R2 * self.weight_network[i]         \n",
    "            if self.KL_probability[i] is not None:\n",
    "                prob, coeff = self.KL_probability[i]\n",
    "                add_dE_dz = - dy_dz * (log(prob) / self.weight_network[i].shape[0])\n",
    "                add_KL_reg = np.dot(add_dE_dz, prev_x) * coeff\n",
    "            else:\n",
    "                add_dE_dz = 0\n",
    "                add_KL_reg = 0\n",
    "            add_weight = add_weight + add_R1 + add_R2 + add_KL_reg       \n",
    "            \n",
    "            self.add_weight[i] = self.add_weight[i]  + add_weight\n",
    "            dE_dz = tmp1_matrix * dy_dz + add_dE_dz\n",
    "            \n",
    "    def add_mean_gradient(self, count_iteration):\n",
    "        for i, layer in enumerate(self.add_weight) : \n",
    "           # print \"layer\" , i\n",
    "           # print \"w\", self.weight_network[i][:3, :3]\n",
    "           # print \"add\", (- self.learning_rate * layer / count_iteration)[:3, :3]\n",
    "            self.weight_network[i] = self.weight_network[i] - self.learning_rate * layer / count_iteration\n",
    "      \n",
    "    def print_weight(self):\n",
    "        for l, layer in enumerate(self.weight_network) :   \n",
    "            print(\"LAYER:\", l, \"shape\", layer.shape)\n",
    "            for n, neuron in enumerate(layer):\n",
    "                print(\"neuron:\", n)\n",
    "                for weight in neuron:\n",
    "                    print(weight)\n",
    "                print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = LambdaRankEstimator()\n",
    "estimator.init(data[0].shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 109) (109,)\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(data):\n",
    "    return (data > 0) * 1.0  - (data < 0) * 1.0\n",
    "\n",
    "def mean_square(y, answer):\n",
    "    return sum((y - answer) ** 2) / 2.0\n",
    "def der_mean_square(y, answer):\n",
    "    return answer - y\n",
    "    \n",
    "def entropy(y, answer) :\n",
    "    return sum(-y * np.log(answer + 1e-20))\n",
    "def der_soft_max(y, answer):\n",
    "    return answer - y\n",
    "    \n",
    "def equal_func(z) :\n",
    "    return z  \n",
    "def one_func (z) :\n",
    "    return 1.0;\n",
    "    \n",
    "def logistic_activation_1(z) :\n",
    "    return logistic_activation_a(1.0, z)\n",
    "def der_logistic_activation_1(z) :\n",
    "    return der_logistic_activation_a(1.0, z)\n",
    "    \n",
    "def max_0(z) :\n",
    "    return (z > 0) * z\n",
    "def der_max_0(z):\n",
    "    return (z > 0) * 1.0\n",
    "\n",
    "                \n",
    "def logistic_activation_a(a, z) :\n",
    "    return 1.0 / (1 + np.exp(-a * z))\n",
    "def der_logistic_activation_a(a, z):\n",
    "    return a*logistic_activation_a(a, z)*(1.0 - logistic_activation_a(a, z))\n",
    "    \n",
    "def load_data() :\n",
    "    path = './big_alphabet_29x29/mutant-'\n",
    "    count_char = 25\n",
    "    count_example = 8\n",
    "    image = rgb2grey(imread('./big_alphabet_29x29/mutant-0-0-0.bmp'))\n",
    "    size = image.shape[0] * image.shape[1]\n",
    "    data_x = np.zeros((count_char * count_example, size))\n",
    "    y = np.zeros(count_char * count_example)    \n",
    "\n",
    "        \n",
    "    for char in range(count_char) :\n",
    "        for i in range(count_example):\n",
    "            path_img = path + str(char) + '-' + str(i) + '-0.bmp'\n",
    "            data_x[char * count_example + i, :] = rgb2grey(imread(path_img)).reshape(size)\n",
    "            y[char * count_example + i] = char\n",
    "    data_x =  data_x - 0.5\n",
    "  #  data_x = data_x / np.max(np.abs(data_x))\n",
    "    return data_x, y \n",
    "    \n",
    "def acurancy(y_pred, y_true):\n",
    "    return float(sum(y_pred == y_true)) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант 3 (Деревья). Более-менее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relNormalize1(rel, max_rel=19):\n",
    "    norm_rel = rel - min(rel)\n",
    "    if max(norm_rel) != 0:\n",
    "        norm_rel = norm_rel * max_rel / max(norm_rel) + 1\n",
    "    return norm_rel\n",
    "\n",
    "def relNormalize2(rel):\n",
    "    uniq_rel = np.unique(rel)\n",
    "    uniq_rel = sorted(uniq_rel)\n",
    "    norm_rel = np.empty(rel.shape)\n",
    "    for i, val in enumerate(uniq_rel):\n",
    "        norm_rel[rel==val] = i + 1\n",
    "    return norm_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QueryData:\n",
    "    def __init__(self, X, rel):\n",
    "        self._X = np.copy(X)\n",
    "        self._n = self._X.shape[0]\n",
    "        self._rel = np.copy(rel)\n",
    "\n",
    "        right_order = np.argsort(self._rel)[::-1]\n",
    "        self._X = self._X[right_order]\n",
    "        self._rel = self._rel[right_order]\n",
    "        self._2_rel = 2 ** self._rel - 1\n",
    "        self._log2_order = np.log2(np.array(range(self._n)) + 2)\n",
    "        \n",
    "    def maxDCG(self, T_NDCG):\n",
    "        return sum(self._2_rel[:T_NDCG] / self._log2_order[:T_NDCG])\n",
    "   \n",
    "    def getX(self):\n",
    "        return self._X\n",
    "    \n",
    "    def getY(self):\n",
    "        return self._rel\n",
    "        \n",
    "    def getSwapNDCGMatrix(self, rel, T_NDCG):\n",
    "        order = np.empty(rel.shape)\n",
    "        sort_rel = sorted(zip(rel, range(rel.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "        order[list(map(lambda x: x[1], sort_rel))] = range(1, rel.shape[0] + 1)\n",
    "        \n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        matr_elem_DCG = np.tile(elem_DCG, (self._n, 1))\n",
    "        matr_swap_elem_DCG = self._2_rel.reshape((self._n, 1)) / log2_order.reshape((1, self._n)) \n",
    "        \n",
    "        lambda_mtr = - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "        no_null_swap = ((order <= T_NDCG).reshape((self._n, 1)) + (order <= T_NDCG).reshape((1, self._n))) > 0 \n",
    "        lambda_mtr = np.abs(lambda_mtr * no_null_swap)\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG != 0:\n",
    "            return lambda_mtr / max_DCG \n",
    "        else:\n",
    "            return lambda_mtr\n",
    "    \n",
    "    def getNDCG(self, rel, T_NDCG):\n",
    "        order = np.empty(rel.shape)\n",
    "        sort_rel = sorted(zip(rel, range(rel.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "        order[list(map(lambda x: x[1], sort_rel))] = range(1, rel.shape[0] + 1)\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        DCG = sum(elem_DCG[order <= T_NDCG])\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG  != 0:\n",
    "            return DCG / max_DCG\n",
    "        else:\n",
    "            return DCG\n",
    "        \n",
    "    def getCountErrorPair(self, rel):\n",
    "        _n = rel.shape[0]\n",
    "        order = np.argsort(rel)[::-1]\n",
    "        pairs = ((- order.reshape((_n, 1)) + order.reshape((1, _n))) > 0)\n",
    "        no_null = ((self._rel.reshape((_n, 1)) - self._rel.reshape((1, _n))) != 0)\n",
    "        count = sum(sum((np.tril(pairs * no_null))))\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 3 0 4 5 6]\n",
      "[[False False  True False  True  True  True]\n",
      " [ True False  True False  True  True  True]\n",
      " [False False False False  True  True  True]\n",
      " [ True  True  True False  True  True  True]\n",
      " [False False False False False  True  True]\n",
      " [False False False False False False  True]\n",
      " [False False False False False False False]]\n",
      "[[False False  True  True  True  True  True]\n",
      " [False False  True  True  True  True  True]\n",
      " [ True  True False False  True  True  True]\n",
      " [ True  True False False  True  True  True]\n",
      " [ True  True  True  True False  True  True]\n",
      " [ True  True  True  True  True False  True]\n",
      " [ True  True  True  True  True  True False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = np.array([5, 5, 4, 4, 3, 2, 1])\n",
    "X = np.array([1, 2, 3, 4, 5, 1, 1])\n",
    "query_data = QueryData(X, rel)\n",
    "query_data.getCountErrorPair(np.array([4, 5, 5, 4, 3, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaRankTrees :\n",
    "    def __init__ (self, learning_rate=0.5, n_estimators=1000, sigma=1, start_depth=5) :\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = None\n",
    "        \n",
    "    def _getTrainX(self, queries_data):\n",
    "        n = 0\n",
    "        m = queries_data[0].getX().shape[1]\n",
    "        for query_data in queries_data:\n",
    "            n += query_data._n\n",
    "            \n",
    "        X = np.empty((n, m), dtype=np.float64)\n",
    "        Y = np.empty(n, dtype=np.float64)\n",
    "        indexs = []\n",
    "        cur_index = 0\n",
    "        for query_data in queries_data:\n",
    "            cur_n = query_data._n\n",
    "            X[cur_index:cur_index + cur_n] = query_data.getX()\n",
    "            Y[cur_index:cur_index + cur_n] = query_data.getY()\n",
    "            indexs.append(range(cur_index,cur_index + cur_n))\n",
    "            cur_index += cur_n            \n",
    "        return X, Y, indexs\n",
    "    \n",
    "    def _getGradient(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        g = np.empty(h.shape[0], dtype=np.float64)\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            rel_n = rel.shape[0]\n",
    "            lambda_matr = np.full((rel_n, rel_n), 1, dtype=np.int) #(- self._sigma / (1 + np.exp(self._sigma * (rel.reshape((1, rel_n)) - -rel.reshape((rel_n, 1)))))) #* query_data.getSwapNDCGMatrix(rel, T_NDCG)\n",
    "\n",
    "            filter_matr = (query_data._rel.reshape((1, rel_n)) - query_data._rel.reshape((rel_n, 1))) != 0\n",
    "            lambda_matr *= filter_matr\n",
    "            tril = np.tril(lambda_matr)\n",
    "            lambda_vector =  np.sum(tril, axis=0) - np.sum(tril.T, axis=0)\n",
    "            g[indexs] = lambda_vector\n",
    "        return g\n",
    "    \n",
    "    def _getNDCG(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        ndcg = 0\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            ndcg+= query_data.getNDCG(rel, T_NDCG)\n",
    "        return ndcg / len(indexs_data)\n",
    "    \n",
    "    def _countErrorPair(self, queries_data, h, indexs_data):\n",
    "        count = 0\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            count += query_data.getCountErrorPair(rel)\n",
    "        return count        \n",
    "    \n",
    "    def fit(self, queries_data, persent_valid=0.2, persent_train=0.1) :\n",
    "        random.seed(1234)\n",
    "        random.shuffle(queries_data)        \n",
    "        count_valid = int(persent_valid * len(queries_data))\n",
    "        data_valid = queries_data[:count_valid]\n",
    "        data_train = queries_data[count_valid:]\n",
    "        \n",
    "        X_train, y_train, index_train = self._getTrainX(data_train)\n",
    "        X_valid, y_valid, index_valid = self._getTrainX(data_valid)\n",
    "        #count_train = int(X_train.shape[0] * persent_train)\n",
    "        #range_train = list(range(0, X_train.shape[0]))\n",
    "        \n",
    "        self._trees = []\n",
    "        self._score_train = []\n",
    "        self._score_valid = []\n",
    "\n",
    "        #d_tree = DT(max_depth=self._start_depth * 10)        \n",
    "        #y_start_train = np.array([random.gauss(mu=1, sigma=1) for i in range(count_train)])\n",
    "        #d_tree.fit(X_train[:count_train], y_start_train) #np.zeros(X_train.shape[0]))\n",
    "        #self._trees.append(d_tree)\n",
    "\n",
    "        #h_train = d_tree.predict(X_train) # np.full(X_train.shape[0], 0) #d_tree.predict(X_train) * self._learning_rate\n",
    "        #h_valid = d_tree.predict(X_valid) # np.full(X_valid.shape[0], 0)# d_tree.predict(X_valid) * self._learning_rate\n",
    "\n",
    "        h_train = np.zeros(X_train.shape[0])\n",
    "        h_valid = np.zeros(X_valid.shape[0])\n",
    "        for iteration in range(self._n_estimators) :\n",
    "            print(iteration, self._countErrorPair(data_train, h_train, index_train),\n",
    "                  self._countErrorPair(data_valid, h_valid, index_valid))\n",
    "            \n",
    "            g = self._getGradient(data_train, h_train, index_train, 10)\n",
    "            norm_g = np.linalg.norm(g)            \n",
    "            \"\"\"\n",
    "            if norm_g > 3 :\n",
    "                d_tree = dt.DecisionTree('mse', self.max_depth, collect_gains_features=self.collect_gains_features)\n",
    "            else :\n",
    "                d_tree = dt.DecisionTree('mse', 3 * self.max_depth, collect_gains_features=self.collect_gains_features)\n",
    "            \"\"\"\n",
    "            #random.shuffle(range_train)\n",
    "            d_tree = DT(max_depth=self._start_depth)\n",
    "            d_tree.fit(X_train, g)\n",
    "            #d_tree.fit(X_train[range_train[:count_train]], -g[range_train[:count_train]])\n",
    "            self._trees.append(d_tree)\n",
    "            h_train += self._learning_rate * d_tree.predict(X_train)\n",
    "            h_valid += self._learning_rate * d_tree.predict(X_valid)\n",
    "            \n",
    "           \n",
    "              #self._getNDCG(data_train, h_train, index_train,10),\n",
    "              #self._getNDCG(data_valid, h_valid, index_valid, 10),\n",
    "              #self._getNDCG(data_train, h_train, index_train, 5),\n",
    "              #self._getNDCG(data_valid, h_valid, index_valid, 5),\n",
    "              #min(g), max(g), norm_g)\n",
    "            #self._score_train.append(self._getNDCG(data_train, h_train, index_train, 5))\n",
    "            #self._score_valid.append(self._getNDCG(data_valid, h_valid, index_valid, 5))\n",
    "            \n",
    "    def predict(self, X) :\n",
    "        y = self._trees[0].predict(X)\n",
    "        for tree in self._trees[1:]:\n",
    "            y += self._learning_rate * tree.predict(X)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    trainPath = \"../data/train.data.cvs\"\n",
    "    return DataFrame.from_csv(trainPath, index_col=False).as_matrix()\n",
    "\n",
    "def loadSmallData():\n",
    "    return np.load(\"small_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowData = loadData()\n",
    "queries = rowData[:, -1]\n",
    "uniq_queries = np.unique(queries)\n",
    "queries_train_data = []\n",
    "for q in uniq_queries:\n",
    "    xy = rowData[queries == q][:, :-1]\n",
    "    queries_train_data.append(QueryData(xy[:, 1:], relNormalize2(xy[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdaRank = LambdaRankTrees(learning_rate=0.01, n_estimators=100, sigma=1, start_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 73529 21641\n",
      "1 96453 31734\n",
      "2 96453 31734\n",
      "3 96453 31734\n",
      "4 96453 31734\n",
      "5 96453 31734\n",
      "6 96453 31734\n",
      "7 96453 31734\n",
      "8 96453 31734\n",
      "9 96453 31734\n",
      "10 96453 31734\n",
      "11 96453 31734\n",
      "12 96453 31734\n",
      "13 96453 31734\n",
      "14 96453 31734\n",
      "15 96453 31734\n",
      "16 96453 31734\n",
      "17 96453 31734\n",
      "18 96453 31734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6e4b8ed7ad61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambdaRank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries_train_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpersent_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersent_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-111a3c4d0577>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, queries_data, persent_valid, persent_train)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m#random.shuffle(range_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0md_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0md_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;31m#d_tree.fit(X_train[range_train[:count_train]], -g[range_train[:count_train]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    375\u001b[0m                                            max_leaf_nodes, self.min_impurity_split)\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdaRank.fit(queries_train_data[:100],  persent_valid=0.2, persent_train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lambdaRank1.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lambdaRankank, \"lambdaRank2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute 'LambdaRankTrees'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-313b0b8f612d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlambdaRank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lambdaRank1.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nina/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute 'LambdaRankTrees'"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "lambdaRank = joblib.load(\"lambdaRank1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03212926,  0.18316964,  0.87774511, ...,  1.45966731,\n",
       "        0.69223217,  0.38776884])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.30000000e+01,   1.30000000e+01,   1.30000000e+01, ...,\n",
       "         2.99980000e+04,   2.99980000e+04,   2.99980000e+04])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRow[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.469031253098\n"
     ]
    }
   ],
   "source": [
    "query_data = queries_train_data[10]\n",
    "ans = lambdaRank.predict(query_data.getX())\n",
    "print(query_data.getNDCG(ans, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207,) (207, 136)\n"
     ]
    }
   ],
   "source": [
    "print(ans.shape, query_data.getX().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel = ans\n",
    "order = np.empty(rel.shape)\n",
    "sort_rel = sorted(zip(rel, range(rel.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "order[list(map(lambda x: x[1], sort_rel))] = range(1, rel.shape[0] + 1)\n",
    "log2_order = np.log2(order + 1)\n",
    "elem_DCG = query_data._2_rel / log2_order\n",
    "DCG = sum(elem_DCG[order <= 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2235622.7682765387"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.maxDCG(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trees = lambdaRank._trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def NDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    best = DCGScore(y_true, y_true, k, gains)\n",
    "    actual = DCGScore(y_true, y_score, k, gains)\n",
    "    return actual / best\n",
    "\n",
    "def deltaNDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    max_DCG = NDCGScore(y_true, y_true, k, gains)\n",
    "    order = np.empty(y_score.shape)\n",
    "    sort_y_score = sorted(zip(y_score, range(y_score.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "    order[list(map(lambda x: x[1], sort_y_score))] = range(1, y_score.shape[0] + 1)\n",
    "    discounts = np.log2(order + 1)    \n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")        \n",
    "    elem_DCG = gains / discounts\n",
    "    _n = y_true.shape[0]\n",
    "    matr_elem_DCG = np.tile(elem_DCG, (_n, 1))\n",
    "    matr_swap_elem_DCG = gains.reshape((_n, 1)) / discounts.reshape((1, _n)) \n",
    "\n",
    "    lambda_mtr = - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "    no_null_swap = ((order <= k).reshape((_n, 1)) + (order <= k).reshape((1, _n))) > 0 \n",
    "    lambda_mtr = np.abs(lambda_mtr * no_null_swap)\n",
    "    \n",
    "    if max_DCG != 0:\n",
    "        return lambda_mtr / max_DCG \n",
    "    else:\n",
    "        return lambda_mtr\n",
    "    \n",
    "def AverageNDCG(data, y_score, k):\n",
    "    uniq_queries = np.unique(data[:, -1])\n",
    "    ndcg = 0\n",
    "    for q in uniq_queries:\n",
    "        filt_q = (data[:, -1] == q)\n",
    "        ndcg += NDCGScore(relNormalize2(data[filt_q, 1]), y_score[filt_q], k)\n",
    "    return ndcg / uniq_queries.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relNormalize2(rel):\n",
    "    uniq_rel = np.unique(rel)\n",
    "    uniq_rel = sorted(uniq_rel)\n",
    "    norm_rel = np.empty(rel.shape)\n",
    "    for i, val in enumerate(uniq_rel):\n",
    "        norm_rel[rel==val] = i + 1\n",
    "    return norm_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   8.73475368,  24.83139624,  63.7642255 ],\n",
       "       [  8.73475368,   0.        ,   0.26185951,   7.        ],\n",
       "       [ 24.83139624,   0.26185951,   0.        ,   4.42884296],\n",
       "       [ 63.7642255 ,   7.        ,   4.42884296,   0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([7, 1, 2, 4])\n",
    "y_score = np.array([1, 2, 3,4])\n",
    "deltaNDCGScore(y_true, y_score, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaRankForest:\n",
    "    def __init__ (self, learning_rate, n_estimators, sigma, start_depth) :\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = []\n",
    "        \n",
    "        \n",
    "    def fit(self, DATA, persent_valid, batch_size, T_NDCG):\n",
    "        all_queries = DATA[:, -1]\n",
    "        uniq_queries = np.unique(all_queries)\n",
    "        random.shuffle(uniq_queries)        \n",
    "        count_valid = int(persent_valid * uniq_queries.shape[0])\n",
    "        \n",
    "        valid_queries = uniq_queries[:count_valid]\n",
    "        train_queries = uniq_queries[count_valid:]\n",
    "        DATA_valid = np.concatenate([DATA[all_queries == q] for q in valid_queries], axis=0)\n",
    "        DATA_train = np.concatenate([DATA[all_queries == q] for q in train_queries], axis=0)\n",
    "        valid_queries = DATA_valid[:, -1]\n",
    "        train_queries = DATA_train[:, -1]\n",
    "        \n",
    "        self._trees = []\n",
    "        h_train = np.array([random.gauss(mu=0, sigma=1) for i in range(DATA_train.shape[0])])\n",
    "        h_valid = np.zeros(DATA_valid.shape[0])\n",
    "        \n",
    "        iteration = 0\n",
    "        while True:\n",
    "            random.shuffle(train_queries)\n",
    "            for i in range(int(train_queries.shape[0] / batch_size)):\n",
    "                batch_queries = train_queries[i * batch_size: (i + 1) * batch_size]\n",
    "                data = np.concatenate([DATA_train[train_queries == q] for q in batch_queries], axis=0)\n",
    "                h_pred = np.concatenate([h_train[train_queries == q] for q in batch_queries])                \n",
    "                X = data[:, 1:-1]\n",
    "                Y_true = data[:, 0]                \n",
    "                \n",
    "                grad = np.empty(Y_true.shape)\n",
    "                for q in batch_queries:\n",
    "                    filter_query = (data[:, -1] == q)\n",
    "                    h = h_pred[filter_query]\n",
    "                    y = relNormalize2(Y_true[filter_query])\n",
    "                    p = 1 + np.exp((h.reshape((h.shape[0], 1)) - h.reshape((1, h.shape[0]))) * self._sigma)\n",
    "                    g = (- self._sigma / p) * deltaNDCGScore(y, h, T_NDCG)\n",
    "                    g = np.tril(g)\n",
    "                    \n",
    "                    grad[filter_query] = np.sum(g, axis=0) - np.sum(g.T, axis=0)\n",
    "                \n",
    "                new_tree = DT(max_depth=self._start_depth)\n",
    "                new_tree.fit(X, -grad)\n",
    "                self._trees.append(new_tree)\n",
    "                \n",
    "                h_train += self._learning_rate * new_tree.predict(DATA_train[:, 1:-1])\n",
    "                h_valid += self._learning_rate * new_tree.predict(DATA_valid[:, 1:-1])\n",
    "                \n",
    "                print (iteration,\n",
    "                       AverageNDCG(DATA_train, h_train, 20),\n",
    "                       AverageNDCG(DATA_valid, h_valid, 20), \n",
    "                       AverageNDCG(DATA_train, h_train, 5), \n",
    "                       AverageNDCG(DATA_valid, h_valid, 5), \n",
    "                       np.linalg.norm(-grad),\n",
    "                       min(-grad),\n",
    "                       max(-grad))\n",
    "                iteration += 1\n",
    "                if (iteration == self._n_estimators):\n",
    "                    break\n",
    "            if (iteration == self._n_estimators):\n",
    "                break\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for tree in self._trees:\n",
    "            y_pred += self._learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.268875510747 0.730170421273 0.127203439044 0.604668713833 inf -1.15945107722e+169 3.41909026892e+170\n",
      "1 0.229356174581 0.827322343813 0.166895104059 0.854817754669 inf -9.0614516453e+215 2.79707958711e+217\n",
      "2 0.198487081215 0.641814272362 0.132887473349 0.554431404046 inf -4.44312249886e+215 3.96709691678e+217\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9cf13dc36f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaRankForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrowData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersent_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_NDCG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-41830017ab83>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, DATA, persent_valid, batch_size, T_NDCG)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 print (iteration,\n\u001b[0;32m---> 56\u001b[0;31m                        \u001b[0mAverageNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                        \u001b[0mAverageNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                        \u001b[0mAverageNDCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6c7823ba737d>\u001b[0m in \u001b[0;36mAverageNDCG\u001b[0;34m(data, y_score, k)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mndcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniq_queries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mfilt_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mndcg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mNDCGScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelNormalize2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt_q\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndcg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0muniq_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = LambdaRankForest(learning_rate=1, n_estimators=100, sigma=1, start_depth=5)\n",
    "estimator.fit(DATA=rowData[:int(rowData.shape[0]/ 2)], persent_valid=0.5, batch_size=100, T_NDCG=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    trainPath = \"../data/train.data.cvs\"\n",
    "    return DataFrame.from_csv(trainPath, index_col=False).as_matrix()\n",
    "rowData = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result  = DataFrame.from_csv(\"result2\", index_col=False).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241521, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rels = result[:, 0]\n",
    "queries = result[:, 1]\n",
    "\n",
    "uniq_queries = np.unique(queries)\n",
    "ans = np.empty((rels.shape[0], 2), dtype=np.int)\n",
    "for q in uniq_queries:\n",
    "    rel = rels[queries == q]    \n",
    "    order = np.argsort(rel) + 1\n",
    "    ans[queries == q, 0] = order \n",
    "    ans[queries == q, 1] = q\n",
    "df = DataFrame(ans, columns=[\"DocumentId\",\"QueryId\"])\n",
    "df.to_csv(open(\"result3\", \"w\"), index=False)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Последний вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "\n",
    "\n",
    "def DCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def NDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    best = DCGScore(y_true, y_true, k, gains)\n",
    "    actual = DCGScore(y_true, y_score, k, gains)\n",
    "    return actual / best\n",
    "\n",
    "def deltaNDCGScore(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    max_DCG = DCGScore(y_true, y_true, k, gains)\n",
    "    order = np.empty(y_score.shape)\n",
    "    sort_y_score = sorted(zip(y_score, range(y_score.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "    order[list(map(lambda x: x[1], sort_y_score))] = range(1, y_score.shape[0] + 1)\n",
    "    discounts = np.log2(order + 1)\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    elem_DCG = gains / discounts\n",
    "    _n = y_true.shape[0]\n",
    "    matr_elem_DCG = np.tile(elem_DCG, (_n, 1))\n",
    "    matr_swap_elem_DCG = gains.reshape((_n, 1)) / discounts.reshape((1, _n))\n",
    "\n",
    "    lambda_mtr = - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "    no_null_swap = ((order <= k).reshape((_n, 1)) + (order <= k).reshape((1, _n))) > 0\n",
    "    lambda_mtr = np.abs(lambda_mtr * no_null_swap)\n",
    "    if max_DCG != 0:\n",
    "        return lambda_mtr / max_DCG\n",
    "    else:\n",
    "        return lambda_mtr\n",
    "\n",
    "def AverageNDCG(data, y_score, k):\n",
    "    uniq_queries = np.unique(data[:, -1])\n",
    "    ndcg = 0\n",
    "    for q in uniq_queries:\n",
    "        filt_q = (data[:, -1] == q)\n",
    "        ndcg += NDCGScore(data[filt_q, 0], y_score[filt_q], k)\n",
    "    return ndcg / uniq_queries.shape[0]\n",
    "\n",
    "def CountErrorPair(data, y_score):\n",
    "    uniq_queries = np.unique(data[:, -1])\n",
    "    count_pair = 0\n",
    "    for q in uniq_queries:\n",
    "        filt_q = (data[:, -1] == q)\n",
    "        y_true = data[filt_q, 0]\n",
    "        right_order = np.argsort(y_true)[::-1]\n",
    "        y_true = y_true[right_order]\n",
    "        y_pred = y_score[filt_q][right_order]\n",
    "\n",
    "        _n = y_pred.shape[0]\n",
    "        order = np.empty(y_pred.shape)\n",
    "        sort_y_pred = sorted(zip(y_pred, range(_n)), key=lambda x: x[0], reverse=True)\n",
    "        order[list(map(lambda x: x[1], sort_y_pred))] = range(1, _n + 1)\n",
    "        pairs = ((order.reshape((_n, 1)) - order.reshape((1, _n))) < 0)\n",
    "        no_null = ((y_true.reshape((_n, 1)) - y_true.reshape((1, _n))) != 0)\n",
    "        count_pair += sum(sum((np.tril(pairs * no_null))))\n",
    "\n",
    "    return count_pair\n",
    "\n",
    "def relNormalize2(rel):\n",
    "    uniq_rel = np.unique(rel)\n",
    "    uniq_rel = sorted(uniq_rel)\n",
    "    norm_rel = np.empty(rel.shape)\n",
    "    for i, val in enumerate(uniq_rel):\n",
    "        norm_rel[rel==val] = i + 1\n",
    "    return norm_rel * 5\n",
    "\n",
    "\n",
    "class LambdaRankForest:\n",
    "    def __init__(self, learning_rate, n_estimators, sigma, start_depth):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = []\n",
    "\n",
    "    def fit(self, DATA, persent_valid, batch_size, normalize, T_NDCG):\n",
    "        all_queries = DATA[:, -1]\n",
    "        uniq_queries = np.unique(all_queries)\n",
    "        for q in uniq_queries:\n",
    "            filt = (all_queries == q)\n",
    "            DATA[filt, 0] = normalize(DATA[filt, 0])\n",
    "            order = np.argsort(DATA[filt, 0])[::-1]\n",
    "            DATA[filt] = DATA[filt][order]\n",
    "\n",
    "        random.shuffle(uniq_queries)\n",
    "        count_valid = int(persent_valid * uniq_queries.shape[0])\n",
    "\n",
    "        valid_queries = uniq_queries[:count_valid]\n",
    "        train_queries = uniq_queries[count_valid:]\n",
    "        DATA_valid = np.concatenate([DATA[all_queries == q] for q in valid_queries], axis=0)\n",
    "        DATA_train = np.concatenate([DATA[all_queries == q] for q in train_queries], axis=0)\n",
    "        v_queries = DATA_valid[:, -1]\n",
    "        t_queries = DATA_train[:, -1]\n",
    "\n",
    "        self._trees = []\n",
    "        #tree = DT()\n",
    "        #tree.fit(DATA_train[:, 1:-1], DATA_train[:, 0])\n",
    "        #self._trees.append(tree)\n",
    "        #h_train = tree.predict(DATA_train[:, 1:-1])\n",
    "        #h_valid = tree.predict(DATA_valid[:, 1:-1])\n",
    "        h_train = np.zeros(DATA_train.shape[0])#np.array([random.gauss(mu=0, sigma=0.1) for i in range(DATA_train.shape[0])])\n",
    "        h_valid = np.zeros(DATA_valid.shape[0])\n",
    "\n",
    "        iteration = 0\n",
    "        while True:            \n",
    "            random.shuffle(train_queries)\n",
    "            for i in range(int(train_queries.shape[0] / batch_size)):\n",
    "                batch_queries = train_queries[i * batch_size: (i + 1) * batch_size]\n",
    "                data = np.concatenate([DATA_train[t_queries == q] for q in batch_queries], axis=0)\n",
    "                h_pred = np.concatenate([h_train[t_queries == q] for q in batch_queries])\n",
    "                X = data[:, 1:-1]\n",
    "                Y_true = data[:, 0]\n",
    "\n",
    "                grad = np.zeros(Y_true.shape)\n",
    "                for q in batch_queries:\n",
    "                    filter_query = (data[:, -1] == q)\n",
    "                    h = h_pred[filter_query]\n",
    "                    y = Y_true[filter_query]\n",
    "                    p = 1 + np.exp((-h.reshape((h.shape[0], 1)) + h.reshape((1, h.shape[0]))) * self._sigma)\n",
    "                    g = (- self._sigma / p) #* deltaNDCGScore(y, h, T_NDCG)\n",
    "                    filt = ((y.reshape((y.shape[0], 1)) - y.reshape((1, y.shape[0]))) != 0)\n",
    "                    g *= filt\n",
    "\n",
    "                    g = np.tril(g)\n",
    "                    xx = np.sum(g, axis=0) - np.sum(g.T, axis=0)\n",
    "                    grad[filter_query] = np.sum(g, axis=0) - np.sum(g.T, axis=0)\n",
    "\n",
    "                new_tree = DT(max_depth=self._start_depth)\n",
    "                new_tree.fit(X, -grad)\n",
    "                self._trees.append(new_tree)\n",
    "\n",
    "                h_train += self._learning_rate * new_tree.predict(DATA_train[:, 1:-1])\n",
    "                h_valid += self._learning_rate * new_tree.predict(DATA_valid[:, 1:-1])\n",
    "\n",
    "                print(iteration,\n",
    "                     CountErrorPair(DATA_train, h_train),\n",
    "                     CountErrorPair(DATA_valid, h_valid),\n",
    "\n",
    "                     AverageNDCG(DATA_train, h_train, 20),\n",
    "                     AverageNDCG(DATA_valid, h_valid, 20),\n",
    "                     AverageNDCG(DATA_train, h_train, 5),\n",
    "                     AverageNDCG(DATA_valid, h_valid, 5),\n",
    "                     np.linalg.norm(-grad),\n",
    "                     min(-grad),\n",
    "                     max(-grad))\n",
    "                 #if (iteration == self._n_estimators):\n",
    "                 #  break\n",
    "            iteration += 1\n",
    "            if (iteration == self._n_estimators):\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for tree in self._trees:\n",
    "            y_pred += self._learning_rate * tree.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "def loadData():\n",
    "    trainPath = \"../data/train.data.cvs\"\n",
    "    return DataFrame.from_csv(trainPath, index_col=False).as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7113895 1701668 0.275989141943 0.262630197077 0.235925855003 0.217294238686 4791.84051279 -124.5 213.5\n",
      "0 8468706 2050739 0.295417163462 0.281304375061 0.240832512657 0.226386152938 4939.89750865 -145.070426875 153.638530511\n",
      "0 9084164 2202678 0.314644622287 0.308923431025 0.253681096515 0.249207837348 5153.16135799 -131.557803398 221.865987354\n",
      "0 9546967 2298959 0.324228535981 0.316900277462 0.2556109273 0.245615378807 4665.94588759 -194.513014767 199.593105806\n",
      "0 9639643 2323256 0.324875444881 0.321655526065 0.255085587945 0.249755214596 4592.78645582 -208.263352352 270.297917544\n",
      "0 9680400 2338475 0.326349353803 0.319212490157 0.25721175175 0.248328634593 5082.42001273 -151.246130315 244.74663774\n",
      "0 9809606 2358543 0.324248977635 0.317215006331 0.254774035272 0.244909049474 4121.25107766 -140.659394504 258.152651073\n",
      "0 9838788 2356440 0.325973644316 0.320076387946 0.253906975239 0.246730958002 4338.08625964 -160.006997133 232.958191986\n",
      "0 9894528 2369550 0.32321088169 0.316284553635 0.250825710179 0.243817808509 5782.40671493 -264.172799755 380.804050387\n",
      "0 9908827 2370299 0.324714486609 0.317902559323 0.251490226951 0.245062108822 5004.0806257 -227.789926555 336.400080819\n",
      "0 9905652 2376943 0.323010756629 0.318688568157 0.250352002852 0.244047086364 5334.19292648 -234.048642746 323.398003059\n",
      "0 9914970 2380999 0.323308916787 0.316534462956 0.249754711781 0.242003109323 4223.35607684 -119.753950145 237.007434077\n",
      "0 9918406 2379527 0.324518294408 0.318086290551 0.252865592356 0.243546984839 4285.67418028 -175.01631071 361.023431289\n",
      "0 9938847 2386858 0.3240630397 0.318677194868 0.252495458825 0.246634987071 4582.99019096 -149.548092764 211.983697854\n",
      "0 9941159 2382512 0.321884826824 0.317263853024 0.249671660466 0.244255103597 4672.17914289 -220.149465005 307.785007283\n",
      "0 9943608 2380498 0.319946355277 0.318368537071 0.247726711164 0.242525229524 6250.11970282 -316.905370196 444.528127089\n",
      "0 9932898 2378105 0.317673591385 0.312956375878 0.244941878075 0.238332464364 4788.5643313 -177.677528791 369.66271578\n",
      "0 9927013 2379435 0.318207917537 0.311510355934 0.245080518005 0.237858241368 5355.33306438 -198.824469091 352.455269246\n",
      "0 9953026 2388850 0.316389007504 0.3098568192 0.243847722182 0.235578333407 6374.44945489 -412.657209978 474.607407138\n",
      "0 9966407 2394830 0.317232854993 0.309229649636 0.242985591746 0.233086213625 4038.4203985 -126.410973391 363.016281732\n",
      "0 9951909 2392100 0.321345771599 0.3116006732 0.247357987084 0.235408651695 4142.31935385 -175.681154875 245.668360935\n",
      "0 9952245 2389767 0.324090000902 0.318072011267 0.250257718924 0.243831030671 4216.59878117 -173.176375405 220.594998128\n",
      "0 9949430 2386198 0.323353805879 0.316788349131 0.248815826557 0.242609301617 3988.48401341 -147.74362169 189.393909837\n",
      "0 9944103 2384325 0.323530455841 0.313130802158 0.24929359925 0.238652580242 4041.87041038 -126.689078202 339.565251398\n",
      "0 9952005 2387024 0.322753847676 0.313804275678 0.249613964648 0.240351031493 4003.41081587 -267.118889379 241.650042298\n",
      "0 9965698 2386713 0.319913592748 0.312666829372 0.247335922333 0.237509284365 4399.96570077 -192.761255299 276.328604669\n",
      "0 9962939 2384528 0.319841832845 0.313191898071 0.245487563998 0.235412700843 3995.61447974 -176.733448801 248.00569922\n",
      "0 9986365 2393478 0.319677902726 0.310026604157 0.244320178077 0.233173395778 5250.99989464 -205.538325196 427.87108872\n",
      "0 9976211 2394766 0.320697078205 0.309403122064 0.244792665813 0.234557921472 4386.6230309 -151.52080259 224.822088552\n",
      "0 9975552 2395194 0.320130352406 0.308883082829 0.24383512599 0.23319599462 3878.26393424 -133.877237691 201.585807987\n",
      "0 9965099 2394885 0.32103741403 0.308359574159 0.244358037588 0.23360998374 4479.07331958 -172.729135935 251.838112048\n",
      "0 9949530 2396568 0.322273742937 0.31066672002 0.245600454437 0.23674168765 5917.43051247 -192.188927825 426.864784255\n",
      "0 9937928 2394855 0.323628730236 0.313258516384 0.247551240055 0.238623801511 4333.5126398 -199.484683564 237.642623189\n",
      "0 9957643 2400532 0.323202709678 0.312740470708 0.247311872373 0.236750208944 3812.84455746 -196.291681786 237.429583957\n",
      "0 9961417 2400353 0.322888481188 0.314042604861 0.248042021738 0.238498193355 5958.8771175 -194.983834015 397.618373964\n",
      "0 9958499 2403496 0.322869157633 0.314145812304 0.247854357129 0.238266943531 4175.99314116 -188.983029996 173.646655844\n",
      "0 9972197 2412309 0.319277248961 0.309761377837 0.244656159487 0.23555867457 5725.84969924 -365.962583911 394.492464277\n",
      "0 9984090 2418238 0.318964967767 0.308407354254 0.24329045015 0.235057111254 5366.26508972 -315.004821336 299.052602661\n",
      "0 9996010 2424984 0.318239015601 0.307041500887 0.242731193176 0.23417969649 5395.27728856 -312.292078481 447.772685771\n",
      "0 9993082 2427458 0.317254002825 0.307237377287 0.242017902658 0.233038612107 4190.74168273 -177.29208454 201.689831413\n",
      "0 10002226 2430190 0.31761069706 0.307592356033 0.24216103291 0.232716858988 6436.19222135 -426.213161105 525.742053996\n",
      "0 10019467 2431863 0.316852345401 0.308081379852 0.241030977942 0.232310672281 6424.44864003 -303.121482204 500.646145647\n",
      "0 10002507 2429473 0.316989460327 0.306703953183 0.240166081499 0.231032607653 5724.88301751 -308.487961536 478.364753018\n",
      "0 10001621 2431206 0.317850390943 0.306707846377 0.241077144276 0.231033082615 5476.33555848 -252.795714133 348.155121326\n",
      "0 9994348 2429530 0.317199210729 0.304639181895 0.240056495543 0.228092071479 4624.61515059 -160.667636804 237.132594504\n",
      "0 9988311 2428691 0.314920603871 0.304533687513 0.237073083229 0.228150884279 5453.53888102 -292.981557205 405.64868253\n",
      "0 9962782 2427435 0.317248666584 0.30898030364 0.240156862761 0.231568592081 4728.24987483 -214.769383095 319.306365293\n",
      "0 9966632 2427347 0.315734486654 0.306785911774 0.238700501088 0.229809745204 8232.46569581 -524.610582966 644.576866447\n",
      "1 9959128 2427459 0.316666683659 0.306079195637 0.23896230538 0.228169474665 6401.25201069 -423.452107301 527.221223482\n",
      "1 9958926 2425991 0.315084282855 0.302083012342 0.238054621226 0.224087904303 4101.91584742 -143.863347967 350.710178019\n",
      "1 9947355 2424375 0.315319566433 0.303370899517 0.238869386831 0.225271098444 4260.55714024 -150.169398917 395.436374391\n",
      "1 9943642 2421430 0.31528494684 0.302822837891 0.238582011892 0.22555907819 4307.06926511 -159.029054002 279.294091759\n",
      "1 9938938 2420660 0.314744362616 0.30258270925 0.237903469882 0.224903063846 4794.71255241 -206.589042008 232.793499401\n",
      "1 9940494 2419871 0.31459033177 0.302462798239 0.237719530784 0.223316809314 4196.25794601 -202.297743244 249.534971575\n",
      "1 9945179 2421014 0.313270738042 0.302445230883 0.236584002281 0.222765722141 4292.85814073 -140.544227165 224.874681504\n",
      "1 9941667 2417102 0.312393640693 0.301716581625 0.235998474084 0.221535486034 3950.77723848 -229.240455342 245.790154032\n",
      "1 9920024 2413695 0.31521112502 0.303767228808 0.238713930266 0.224654061447 5014.29933884 -178.479275873 233.375509257\n",
      "1 9910503 2410195 0.316088974885 0.303791022182 0.240280161134 0.225344026683 4667.39962846 -140.30272458 242.351002206\n",
      "1 9910783 2410723 0.315951881689 0.302559343154 0.239896534731 0.223495929722 4895.57284861 -226.919243806 411.049536323\n",
      "1 9904004 2407866 0.318933122136 0.3063857485 0.24265402043 0.227725596588 4362.04366704 -185.876141098 212.565351784\n",
      "1 9885420 2404558 0.318559043062 0.304584818744 0.241909368901 0.225903887298 7154.21244113 -530.173983328 653.6340926\n",
      "1 9884471 2404720 0.32044413139 0.307218621661 0.243688542967 0.228583450852 5461.8483542 -313.982722682 394.90975919\n",
      "1 9867888 2400763 0.320137567574 0.307850439851 0.242140078611 0.228373068564 5322.5076425 -248.2998673 377.854292135\n",
      "1 9870696 2405140 0.320543595869 0.305892779407 0.242218083793 0.227589837163 3924.97059991 -137.358134487 230.942499536\n",
      "1 9878697 2410203 0.319563070431 0.30461185946 0.240836861659 0.224989236637 6428.89620169 -277.616719539 472.410649221\n",
      "1 9881008 2411936 0.318713038808 0.303604338335 0.240527647141 0.222619556455 4750.77183273 -184.297902702 258.32932906\n",
      "1 9882242 2411921 0.318047247269 0.303585192569 0.241103123795 0.221937544688 5026.71771018 -264.204660678 406.40881805\n",
      "1 9902685 2419778 0.319047364433 0.303682044766 0.242329708472 0.222779142311 4849.3273534 -226.97092736 354.661756768\n",
      "1 9893631 2417682 0.320654958055 0.30421589478 0.243510115994 0.224308084458 3414.34351232 -188.599940289 274.632603397\n",
      "1 9899208 2417981 0.319758615053 0.304670265825 0.242426850596 0.224071534278 4286.68861755 -176.486608626 262.867402594\n",
      "1 9894058 2418162 0.32144467109 0.308069589255 0.244636009801 0.229378243786 6524.48771172 -307.981151389 535.290897724\n",
      "1 9889692 2418181 0.320925033701 0.306823472513 0.243726578383 0.228393328333 5016.14389163 -383.945672847 391.182839402\n",
      "1 9875708 2416409 0.320444734399 0.306919652898 0.242460158135 0.227833940437 4888.35066494 -172.226572602 445.029556415\n",
      "1 9882332 2417370 0.319550194887 0.306217545231 0.241639846616 0.226333870124 5505.26668783 -230.078742211 428.782340549\n",
      "1 9885171 2417680 0.318596065339 0.305785635099 0.240613713019 0.227006183702 4443.8604713 -238.123409984 286.07540885\n",
      "1 9969181 2432326 0.314145414097 0.302406255392 0.235750563994 0.224322912259 5585.9593044 -316.150877304 383.11679473\n",
      "1 9960025 2429629 0.314363954952 0.301423938045 0.235733283754 0.223024747736 4426.94958981 -214.590075268 337.240958684\n",
      "1 9947658 2427011 0.314739271161 0.303424455275 0.235426171549 0.224250200432 4243.04892877 -217.124767118 276.443724329\n",
      "1 9947707 2425675 0.314913812455 0.30389914446 0.236155701203 0.224573906438 4474.13711965 -171.187933047 241.625520547\n",
      "1 9935647 2426921 0.316123899187 0.303296538813 0.237896571256 0.223721348662 3438.1651671 -130.702445542 195.157453952\n",
      "1 9935963 2425698 0.315257009424 0.302934732354 0.23697577603 0.224876089406 5724.8212896 -283.266410634 367.994399922\n",
      "1 9945708 2429148 0.315160255251 0.303228346508 0.236792045758 0.225606575718 5194.5229373 -298.094158861 401.235912966\n",
      "1 9946145 2430522 0.316404156386 0.304026466466 0.237642384845 0.225948226991 4733.3584097 -245.982204886 322.922051303\n",
      "1 9949919 2432845 0.315857079717 0.301660542576 0.237613287205 0.225304953338 3528.19860508 -198.560642518 237.374151179\n",
      "1 9947399 2431909 0.315419161882 0.301964966881 0.237012262569 0.225951546146 4178.02141671 -191.1479419 244.018718469\n",
      "1 9938341 2428909 0.315579211755 0.304389341905 0.237236532574 0.226517394091 3790.15004335 -185.080163121 221.15397632\n",
      "1 9944560 2429829 0.315671844318 0.304501255776 0.237569051686 0.226850421041 4492.64923612 -170.284021963 236.075692331\n",
      "1 9942215 2431677 0.317634229429 0.30516808177 0.239652025882 0.228967300587 5790.77248514 -323.216898506 434.073585008\n",
      "1 9943267 2432789 0.316658802153 0.304865715611 0.238559271034 0.228045358419 5108.19735438 -219.762105508 265.797572743\n",
      "1 9956974 2436997 0.316934232506 0.305145142754 0.238735159735 0.227238628906 6066.97205647 -291.293513804 362.060553977\n",
      "1 9964726 2439153 0.316932116635 0.305977938764 0.23886573821 0.228936336876 6623.36037391 -315.871481192 484.107140334\n",
      "1 9964262 2440167 0.315100053569 0.304928698624 0.238542109699 0.22830639884 5443.47857689 -262.405245843 521.734247157\n",
      "1 9977255 2442905 0.313330966227 0.302380125083 0.236161340935 0.225257555075 4944.78053787 -226.583191656 255.426117114\n",
      "1 9976161 2443514 0.313497712518 0.304208149114 0.235755367879 0.226984077317 3642.24258302 -141.651034912 187.834703558\n",
      "1 9973072 2443050 0.314908378597 0.305144149816 0.236717070517 0.227918321672 5367.39434432 -191.141824595 448.928222152\n",
      "1 9959551 2439385 0.314661100233 0.304457491725 0.236661177852 0.227568638278 6303.58351244 -416.884473084 562.570582904\n",
      "2 9968278 2440965 0.314299826482 0.304894399405 0.236777970301 0.226900664858 5361.58067415 -221.153821375 382.950242749\n",
      "2 9976188 2443925 0.313838104996 0.305173746644 0.236066362812 0.22555177609 5791.36638244 -319.028722961 503.733146695\n",
      "2 9966423 2444141 0.312854365753 0.304151768241 0.23576171705 0.224550374962 3996.27677261 -170.403853398 226.304203644\n",
      "2 9954724 2442591 0.312022943075 0.303223844718 0.234514532978 0.224186694013 6346.62296468 -307.27607836 542.253130602\n",
      "2 9962334 2442946 0.312208452006 0.305269951626 0.234087234646 0.225641083067 4210.32082337 -173.471107403 247.663690763\n",
      "2 9953877 2442004 0.312465836301 0.306467732634 0.23370094036 0.227313867616 4750.66757725 -157.775536335 291.437101824\n",
      "2 9955223 2443086 0.31233435962 0.304853382861 0.23322271269 0.224846785902 4316.63768754 -183.156184592 194.106552609\n",
      "2 9960733 2443501 0.31078212783 0.303769932452 0.231493212422 0.224763552132 5200.41047741 -257.782316641 276.92696513\n",
      "2 9957818 2443495 0.311930356153 0.304109683389 0.233703191538 0.225477172976 4479.95253663 -164.39557644 283.214962356\n",
      "2 9961685 2444567 0.312695975322 0.304452073573 0.234151554309 0.225598762266 3657.19822572 -150.619361586 192.612402432\n",
      "2 9963909 2444444 0.312760107793 0.303500515338 0.234159497314 0.22423587849 6864.76577615 -532.478253478 665.710051825\n",
      "2 9957248 2442284 0.312083131245 0.301955385686 0.233419261374 0.223168124377 3948.35862361 -209.544508205 170.202986034\n",
      "2 9959983 2441918 0.312152191886 0.301164798214 0.233182232082 0.221213992205 3597.1106506 -183.833220735 190.955031749\n",
      "2 9955331 2442856 0.312379757118 0.301204467161 0.233290558195 0.224219334345 5598.01516633 -303.233872699 414.379873507\n",
      "2 9955298 2444753 0.312389083713 0.302198115205 0.232835292528 0.224527294447 4306.08427623 -235.26721248 433.166630879\n",
      "2 9962941 2447911 0.31289460046 0.305070460127 0.233686946766 0.228136037721 4100.7725854 -147.054273585 241.339726142\n",
      "2 9956642 2445966 0.313742624097 0.306345258616 0.234797965773 0.228988777415 3785.56782884 -189.503412451 219.353460573\n",
      "2 9963667 2449002 0.312937455264 0.305046505239 0.234658512129 0.227831316046 4996.92321685 -292.90718334 433.605147951\n",
      "2 9966635 2449636 0.313825263035 0.304886819065 0.235518335337 0.229662701121 4176.2784089 -177.922360726 278.518141796\n",
      "2 9970067 2451204 0.313788520031 0.305255644154 0.235850489528 0.229623100631 5318.1550801 -252.320637021 341.441324208\n",
      "2 9970132 2451418 0.313218640474 0.305937753769 0.234163096878 0.230570542537 4248.05069805 -153.506472135 221.222704939\n",
      "2 9973052 2451961 0.313696035806 0.306402949972 0.234194134694 0.23078048269 4101.77987119 -180.05544988 304.12657523\n",
      "2 9976535 2452536 0.311592405594 0.303212838512 0.232037124488 0.226849566794 5803.71813407 -245.702212095 419.19594043\n",
      "2 9968495 2449087 0.311309743274 0.302419918404 0.231595464883 0.225382494567 4372.69926745 -194.147610633 242.390516925\n",
      "2 9964388 2448612 0.312352557468 0.30306252398 0.232483713334 0.224931873607 4046.09966744 -165.970967017 238.373523875\n",
      "2 9959260 2446021 0.310611817372 0.302089982154 0.230550421903 0.222871295978 5727.0017581 -292.602523308 374.609516487\n",
      "2 9950756 2444126 0.310768522189 0.302084235412 0.231195414979 0.222012239313 4758.78566106 -214.687885844 373.284695\n",
      "2 9953687 2446476 0.310548910822 0.30192497483 0.23022228154 0.222701318226 5314.10904689 -220.320815804 401.824804631\n",
      "2 9954512 2447974 0.310260822187 0.301525858561 0.229550846078 0.22205444178 4271.67983991 -187.055837808 248.117365036\n",
      "2 9956182 2447816 0.310623718313 0.30139851881 0.22871700754 0.219921524782 5587.03496031 -380.886446078 434.550212235\n",
      "2 9951365 2447471 0.310631722191 0.300921030334 0.229355464624 0.218431059465 4621.64164977 -198.539151445 261.006783351\n",
      "2 9959244 2453475 0.310238014515 0.300539701316 0.229205137327 0.218321656818 5227.80190942 -258.23375362 362.649613704\n",
      "2 9957773 2453625 0.311761057167 0.303134123292 0.231402387587 0.221221282144 4736.7010443 -165.584934395 265.516869043\n",
      "2 9953696 2453157 0.311450521434 0.302756221634 0.231258294981 0.220890330951 3675.20765655 -180.607099149 188.652956893\n",
      "2 9951374 2452582 0.311503144652 0.300715685275 0.231228474765 0.218726184558 4293.26796817 -150.820247274 201.76907844\n",
      "2 9954745 2455818 0.311262566811 0.300122639402 0.230498785958 0.218071110596 4641.80446606 -236.917839562 303.513294359\n",
      "2 9959707 2455950 0.31115636603 0.300019191572 0.230657307858 0.217435138286 4273.05162321 -167.399224178 238.126385963\n",
      "2 9956124 2453304 0.310839872825 0.299526948267 0.230606190547 0.218220208556 5531.77005328 -179.066919102 351.977885351\n",
      "2 9960284 2455466 0.311241081224 0.300288456459 0.230447618111 0.220152031364 7263.41706217 -417.292261666 526.718138609\n",
      "2 9960644 2456597 0.311413773767 0.299949053778 0.230485898511 0.220107764766 5132.44998328 -274.217331264 454.099056517\n",
      "2 9971978 2459700 0.312500330295 0.300544314966 0.231692887523 0.219137413432 5701.20464736 -248.547916928 388.399989234\n",
      "2 9973140 2461467 0.312595093624 0.301156352517 0.232311420865 0.218954450077 6994.04548492 -427.065025032 546.251027481\n",
      "2 9968826 2457217 0.312580089026 0.301385612459 0.232149558442 0.218454702554 4969.87435857 -238.986282488 343.452695914\n",
      "2 9967815 2457448 0.311974224472 0.301857245377 0.231370783289 0.218680627594 6190.27413039 -325.952413622 438.153588814\n",
      "2 9961140 2456703 0.313015676056 0.303065591547 0.23228168669 0.220377861833 5979.41765414 -302.830680469 356.897295236\n",
      "2 9971894 2460857 0.315184521123 0.304925941704 0.234679469856 0.221298054335 4321.52552366 -132.624497489 338.786356787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cbbaf4865b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrowData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaRankForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrowData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersent_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelNormalize2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_NDCG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-135c191badac>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, DATA, persent_valid, batch_size, normalize, T_NDCG)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 print(iteration,\n\u001b[0;32m--> 155\u001b[0;31m                      \u001b[0mCountErrorPair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                      \u001b[0mCountErrorPair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c191badac>\u001b[0m in \u001b[0;36mCountErrorPair\u001b[0;34m(data, y_score)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniq_queries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mfilt_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mright_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rowData = loadData()\n",
    "estimator = LambdaRankForest(learning_rate=0.01, n_estimators=100, sigma=1, start_depth=5)\n",
    "estimator.fit(DATA=rowData, persent_valid=0.2, batch_size=100, normalize=relNormalize2, T_NDCG=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveResults(queries, rels, namefile):\n",
    "    uniq_queries = np.unique(queries)\n",
    "    ans = np.empty((rels.shape[0], 2), dtype=np.int)\n",
    "    count_last = 0\n",
    "    for q in uniq_queries:\n",
    "        rel = rels[queries == q]\n",
    "        order = np.argsort(rel)[::-1] + 1 + count_last\n",
    "        ans[queries == q, 0] = order \n",
    "        ans[queries == q, 1] = q\n",
    "        count_last += q.shape[0]\n",
    "    df = DataFrame(ans, columns=[\"DocumentId\",\"QueryId\"])\n",
    "    df.to_csv(open(namefile, \"w\"), index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dc1f5305e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestRow\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/testset.cvs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaveResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestRow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"result4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "testRow  = DataFrame.from_csv(\"../data/testset.cvs\", index_col=False).as_matrix()\n",
    "ans = estimator.predict()\n",
    "saveResults(testRow[:, -1], ans, \"result4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

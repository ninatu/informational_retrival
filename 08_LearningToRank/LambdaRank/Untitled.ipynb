{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relNormalize1(rel, max_rel=19):\n",
    "    norm_rel = rel - min(rel)\n",
    "    if max(norm_rel) != 0:\n",
    "        norm_rel = norm_rel * max_rel / max(norm_rel) + 1\n",
    "    return norm_rel\n",
    "\n",
    "def relNormalize2(rel):\n",
    "    uniq_rel = np.unique(rel)\n",
    "    uniq_rel = sorted(uniq_rel)\n",
    "    norm_rel = np.empty(rel.shape)\n",
    "    for i, val in enumerate(uniq_rel):\n",
    "        norm_rel[rel==val] = i + 1\n",
    "    return norm_rel * 5\n",
    "\n",
    "\n",
    "class QueryData:\n",
    "    def __init__(self, X, rel):\n",
    "        self._X = np.copy(X)\n",
    "        self._n = self._X.shape[0]\n",
    "        self._rel = np.copy(rel)\n",
    "\n",
    "        right_order = np.argsort(self._rel)[::-1]\n",
    "        self._X = self._X[right_order]\n",
    "        self._rel = self._rel[right_order]\n",
    "        self._2_rel = 2 ** self._rel - 1\n",
    "        self._log2_order = np.log2(np.array(range(self._n)) + 2)\n",
    "\n",
    "    def maxDCG(self, T_NDCG):\n",
    "        return sum(self._2_rel[:T_NDCG] / self._log2_order[:T_NDCG])\n",
    "\n",
    "    def getX(self):\n",
    "        return self._X\n",
    "\n",
    "    def getY(self):\n",
    "        return self._rel\n",
    "\n",
    "    def getSwapNDCGMatrix(self, rel, T_NDCG):\n",
    "        order = np.empty(rel.shape)\n",
    "        sort_rel = sorted(zip(rel, range(rel.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "        order[list(map(lambda x: x[1], sort_rel))] = range(1, rel.shape[0] + 1)\n",
    "\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        matr_elem_DCG = np.tile(elem_DCG, (self._n, 1)).T\n",
    "        matr_swap_elem_DCG = (self._2_rel.reshape((1, self._n)) / log2_order.reshape((self._n, 1))).T\n",
    "\n",
    "        lambda_mtr = - matr_elem_DCG - matr_elem_DCG.T + matr_swap_elem_DCG + matr_swap_elem_DCG.T\n",
    "        no_null_swap = ((order <= T_NDCG).reshape((self._n, 1)) + (order <= T_NDCG).reshape((1, self._n))) > 0\n",
    "        lambda_mtr = np.abs(lambda_mtr * no_null_swap)\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG != 0:\n",
    "            return lambda_mtr / max_DCG\n",
    "        else:\n",
    "            return lambda_mtr\n",
    "\n",
    "    def getNDCG(self, rel, T_NDCG):\n",
    "        order = np.empty(rel.shape)\n",
    "        sort_rel = sorted(zip(rel, range(rel.shape[0])), key=lambda x: x[0], reverse=True)\n",
    "        order[list(map(lambda x: x[1], sort_rel))] = range(1, rel.shape[0] + 1)\n",
    "        log2_order = np.log2(order + 1)\n",
    "        elem_DCG = self._2_rel / log2_order\n",
    "        DCG = sum(elem_DCG[order <= T_NDCG])\n",
    "        max_DCG = self.maxDCG(T_NDCG)\n",
    "        if max_DCG != 0:\n",
    "            return DCG / max_DCG\n",
    "        else:\n",
    "            return DCG\n",
    "\n",
    "    def getCountErrorPair(self, rel):\n",
    "        _n = rel.shape[0]\n",
    "        pairs = (rel.reshape((_n, 1)) - rel.reshape((1, _n)) <= 0)\n",
    "        true_pairs = (self._rel.reshape((_n, 1)) - self._rel.reshape((1, _n)) > 0)\n",
    "        count = sum(sum(pairs == true_pairs))\n",
    "        return count\n",
    "\n",
    "\n",
    "class LambdaRankTrees:\n",
    "    def __init__(self, learning_rate=0.5, n_estimators=1000, sigma=1, start_depth=5):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._n_estimators = n_estimators\n",
    "        self._sigma = sigma\n",
    "        self._start_depth = start_depth\n",
    "        self._trees = None\n",
    "\n",
    "    def _getTrainX(self, queries_data):\n",
    "        n = 0\n",
    "        m = queries_data[0].getX().shape[1]\n",
    "        for query_data in queries_data:\n",
    "            n += query_data._n\n",
    "\n",
    "        X = np.empty((n, m), dtype=np.float64)\n",
    "        Y = np.empty(n, dtype=np.float64)\n",
    "        indexs = []\n",
    "        cur_index = 0\n",
    "        for query_data in queries_data:\n",
    "            cur_n = query_data._n\n",
    "            X[cur_index:cur_index + cur_n] = query_data.getX()\n",
    "            Y[cur_index:cur_index + cur_n] = query_data.getY()\n",
    "            indexs.append(range(cur_index, cur_index + cur_n))\n",
    "            cur_index += cur_n\n",
    "        return X, Y, indexs\n",
    "\n",
    "    def _getGradient(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        g = np.empty(h.shape[0], dtype=np.float64)\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            rel_n = rel.shape[0]\n",
    "            \n",
    "            delta_rels = rel.reshape((rel_n, 1)) - rel.reshape((1, rel_n))\n",
    "            sign_matr = np.sign(query_data._rel.reshape((rel_n, 1)) - query_data._rel.reshape((1, rel_n)))\n",
    "            \n",
    "            lambda_matr = - self._sigma / (1 + np.exp(self._sigma * (sign_matr * delta_rels))) #* query_data.getSwapNDCGMatrix(rel, T_NDCG)\n",
    "            lambda_vector = np.sum(lambda_matr * sign_matr, axis=1)\n",
    "            g[indexs] = lambda_vector\n",
    "        return g\n",
    "\n",
    "    def _getNDCG(self, queries_data, h, indexs_data, T_NDCG):\n",
    "        ndcg = 0\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            ndcg += query_data.getNDCG(rel, T_NDCG)\n",
    "        return ndcg / len(indexs_data)\n",
    "\n",
    "    def _countErrorPair(self, queries_data, h, indexs_data):\n",
    "        count = 0\n",
    "        for i, indexs in enumerate(indexs_data):\n",
    "            query_data = queries_data[i]\n",
    "            rel = h[indexs]\n",
    "            count += query_data.getCountErrorPair(rel)\n",
    "        return count\n",
    "\n",
    "    def fit(self, queries_data, persent_valid=0.2, persent_train=0.1):\n",
    "        random.seed(1234)\n",
    "        random.shuffle(queries_data)\n",
    "        count_valid = int(persent_valid * len(queries_data))\n",
    "        data_valid = queries_data[:count_valid]\n",
    "        data_train = queries_data[count_valid:]\n",
    "        #data_train = queries_data\n",
    "\n",
    "        X_train, y_train, index_train = self._getTrainX(data_train)\n",
    "        X_valid, y_valid, index_valid = self._getTrainX(data_valid)\n",
    "        self._trees = []\n",
    "        self._score_train = []\n",
    "        self._score_valid = []\n",
    "\n",
    "        h_train = np.zeros(X_train.shape[0])\n",
    "        h_valid = np.zeros(X_valid.shape[0])\n",
    "        for iteration in range(self._n_estimators):\n",
    "            print(iteration, self._countErrorPair(data_train, h_train, index_train),\n",
    "                 self._getNDCG(data_train, h_train, index_train, 5),\n",
    "                    self._countErrorPair(data_valid, h_valid, index_valid),\n",
    "                 self._getNDCG(data_valid, h_valid, index_valid, 5))\n",
    "                  #self._countErrorPair(data_valid, h_valid, index_valid))\n",
    "\n",
    "            g = self._getGradient(data_train, h_train, index_train, 5)\n",
    "            norm_g = np.linalg.norm(g)\n",
    "            d_tree = DT(max_depth=self._start_depth)\n",
    "            d_tree.fit(X_train, -g)\n",
    "            self._trees.append(d_tree)\n",
    "            h_train += self._learning_rate * d_tree.predict(X_train)\n",
    "            h_valid += self._learning_rate * d_tree.predict(X_valid)\n",
    "\n",
    "            # self._score_train.append(self._getNDCG(data_train, h_train, index_train, 5))\n",
    "            # self._score_valid.append(self._getNDCG(data_valid, h_valid, index_valid, 5))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        for tree in self._trees:\n",
    "            y += self._learning_rate * tree.predict(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    trainPath = \"../data/train.data.cvs\"\n",
    "    return DataFrame.from_csv(trainPath, index_col=False).as_matrix()\n",
    "\n",
    "def loadSmallData():\n",
    "    return np.load(\"small_train.npy\")\n",
    "\n",
    "def saveResults(queries, rels, namefile):\n",
    "    uniq_queries = np.unique(queries)\n",
    "    ans = np.empty((rels.shape[0], 2), dtype=np.int)\n",
    "    count_last = 1\n",
    "    for q in uniq_queries:\n",
    "        rel = rels[queries == q]\n",
    "        order = np.argsort(rel)[::-1] + count_last\n",
    "        ans[queries == q, 0] = order\n",
    "        ans[queries == q, 1] = q\n",
    "        count_last += rel.shape[0]\n",
    "    df = DataFrame(ans, columns=[\"DocumentId\",\"QueryId\"])\n",
    "    df.to_csv(open(namefile, \"w\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowData = loadData()\n",
    "queries = rowData[:, -1]\n",
    "uniq_queries = np.unique(queries)\n",
    "queries_train_data = []\n",
    "for q in uniq_queries:\n",
    "    xy = rowData[queries == q][:, :-1]\n",
    "    queries_train_data.append(QueryData(xy[:, 1:], relNormalize2(xy[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 399473 1.0 90192 1.0\n",
      "1 487186 0.533776922199 118954 0.519584561941\n",
      "2 515663 0.418377136398 128709 0.305555980655\n",
      "3 534854 0.310619018379 139662 0.247833237414\n",
      "4 554289 0.287308435629 145494 0.180033614185\n",
      "5 558152 0.305391162919 146105 0.172047591539\n",
      "6 563510 0.310972838815 147089 0.182001643566\n",
      "7 562327 0.324291592039 146570 0.182740821549\n",
      "8 572685 0.322599230749 149363 0.199512361289\n",
      "9 572657 0.319773661693 150411 0.183796296259\n",
      "10 569199 0.321288210565 150364 0.176241442038\n",
      "11 569176 0.303841611092 151335 0.150391362026\n",
      "12 566094 0.29228471327 151599 0.150660018101\n",
      "13 564448 0.28850971441 152366 0.148324758515\n",
      "14 560442 0.308838636885 151871 0.181408298993\n",
      "15 558741 0.315289773458 152178 0.153269906116\n",
      "16 556063 0.295094631082 152286 0.145730947229\n",
      "17 554518 0.295777843657 152592 0.136793629678\n",
      "18 552815 0.300542527124 152734 0.139305687676\n",
      "19 551484 0.298487354992 152568 0.139298616342\n",
      "20 550434 0.297111576212 153181 0.140132892235\n",
      "21 549530 0.305230316704 153659 0.137317770241\n",
      "22 546946 0.328655806103 153640 0.163527442312\n",
      "23 544276 0.332678615215 153534 0.167292504291\n",
      "24 543148 0.324569693437 153762 0.167292601426\n",
      "25 539590 0.337148804813 153965 0.169808433273\n",
      "26 537978 0.328041281149 154030 0.160063088808\n",
      "27 534978 0.333377978918 154674 0.162648998936\n",
      "28 532387 0.337629069589 154603 0.154783931055\n",
      "29 531340 0.332865171415 154145 0.167264996754\n",
      "30 530418 0.34224327001 154294 0.205988719082\n",
      "31 527206 0.325616303583 155601 0.190185342939\n",
      "32 525617 0.32040078452 155682 0.1942647896\n",
      "33 524360 0.321909231421 155908 0.188513179917\n",
      "34 522744 0.323750835356 155955 0.198492797444\n",
      "35 521266 0.338084447659 155923 0.197349982893\n",
      "36 518590 0.331071919898 156055 0.196668486254\n",
      "37 517087 0.326402041989 155877 0.18621304482\n",
      "38 514077 0.332241512346 156339 0.202467704485\n",
      "39 512861 0.33646355944 156339 0.203465531707\n",
      "40 511769 0.347911547432 156150 0.20412165101\n",
      "41 510445 0.347994415635 156534 0.216490432779\n",
      "42 509331 0.345747546748 156640 0.219014801969\n",
      "43 507189 0.355567730486 156581 0.219453580394\n",
      "44 504854 0.356075969817 156312 0.219625642869\n",
      "45 504023 0.360356514215 156200 0.214273984973\n",
      "46 502498 0.362207732989 155813 0.236592964193\n",
      "47 500778 0.358139997252 155835 0.236146674852\n",
      "48 499477 0.347639115173 155805 0.25116984027\n",
      "49 497639 0.349696396347 155693 0.251170426159\n",
      "50 496588 0.349000654863 155639 0.251170426159\n",
      "51 494781 0.349530138684 155749 0.23884654527\n",
      "52 492519 0.349288284867 156038 0.238386577597\n",
      "53 490969 0.351652735489 155788 0.238007743157\n",
      "54 489069 0.357105177354 156607 0.248068785275\n",
      "55 488005 0.357484974056 157185 0.248068785275\n",
      "56 486960 0.35656510093 156648 0.25241532823\n",
      "57 485955 0.347232934996 156410 0.253371839951\n",
      "58 484625 0.353678972797 156540 0.238121039998\n",
      "59 483535 0.350870987043 156534 0.23796626554\n",
      "60 482573 0.351423991974 156388 0.232624900812\n",
      "61 481028 0.34878551249 156550 0.250195576941\n",
      "62 479912 0.34762621873 156698 0.25813366727\n",
      "63 477896 0.349644441776 156547 0.25297201267\n",
      "64 476767 0.348965331873 156715 0.252713324098\n",
      "65 474832 0.346821252255 157207 0.252713324098\n",
      "66 472893 0.362425676427 157052 0.255360655657\n",
      "67 471702 0.355885521241 157183 0.275349587539\n",
      "68 470766 0.367472060912 157181 0.280270741122\n",
      "69 469531 0.36260570586 157111 0.282105641522\n",
      "70 468343 0.364655885286 157175 0.256665110329\n",
      "71 466883 0.355478439184 156907 0.258173163184\n",
      "72 465651 0.359311380645 157425 0.258411130512\n",
      "73 464539 0.364963848001 157908 0.229043065629\n",
      "74 463768 0.370193223769 157760 0.224841090277\n",
      "75 462413 0.362035968031 158036 0.230283120634\n",
      "76 461015 0.371775317862 158084 0.235147820124\n",
      "77 460123 0.380900279947 158364 0.225035993589\n",
      "78 459452 0.379173678097 158320 0.226921530511\n",
      "79 458175 0.382594231654 158784 0.225539164183\n",
      "80 456971 0.379744713903 158144 0.234483768962\n",
      "81 456407 0.381707270612 158260 0.234318295228\n",
      "82 455431 0.381535961175 158236 0.242551221859\n",
      "83 454511 0.380686316709 157844 0.233193773302\n",
      "84 453790 0.388231727222 157894 0.227118989436\n",
      "85 452717 0.387803151796 157926 0.226508969467\n",
      "86 451709 0.388845928721 157634 0.226505617498\n",
      "87 450556 0.39394421874 157694 0.238255671062\n",
      "88 449836 0.40460334614 157910 0.233736884088\n",
      "89 448820 0.410866118652 157550 0.210343190009\n",
      "90 447840 0.411892987609 157633 0.214502837975\n",
      "91 447002 0.413860456955 157585 0.214937299832\n",
      "92 446150 0.407764276614 157240 0.211498027598\n",
      "93 445650 0.409984907537 157358 0.211848394369\n",
      "94 444964 0.409753105783 157537 0.211667327893\n",
      "95 443937 0.408414102761 158015 0.210932338125\n",
      "96 443160 0.409238402914 158244 0.216656033231\n",
      "97 441674 0.410119520079 158739 0.221766576658\n",
      "98 441221 0.407895721609 158841 0.221764942408\n",
      "99 440230 0.405928600242 159103 0.215927290522\n"
     ]
    }
   ],
   "source": [
    "lambdaRank = LambdaRankTrees(learning_rate=0.1, n_estimators=100, sigma=1, start_depth=3)\n",
    "lambdaRank.fit(queries_train_data[:120],  persent_valid=0.2, persent_train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRow  = DataFrame.from_csv(\"../data/testset.cvs\", index_col=False).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = lambdaRank.predict(testRow[:, 1:-1])\n",
    "saveResults(testRow[:, -1], ans, \"result9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
